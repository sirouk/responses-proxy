# OpenAI Responses Proxy Configuration

# Backend configuration
BACKEND_URL=https://llm.chutes.ai/v1/chat/completions
BACKEND_TIMEOUT_SECS=600

# Proxy configuration
HOST_PORT=8282
RUST_LOG=info

# Circuit breaker (optional)
ENABLE_CIRCUIT_BREAKER=false

# Logging configuration
ENABLE_LOG_VOLUME=false

# Caddy configuration
CADDY_DOMAIN=responses-proxy.chutes.ai
CADDY_PORT=443
CADDY_TLS=true
