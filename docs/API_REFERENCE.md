# API Reference - OpenAI Responses Proxy

## Endpoints

### POST /v1/responses

Create a model response using the OpenAI Responses API format.

**Request Headers:**
- `Authorization: Bearer <api_key>` (required) - API key forwarded to Chutes.ai
- `Content-Type: application/json` (required)

**Request Body:**

```json
{
  "model": "gpt-4o",              // Required: Model name
  "input": "...",                 // Required: String or array of input items
  "instructions": "...",          // Optional: System instructions
  "max_output_tokens": 1024,     // Optional: Max tokens to generate
  "temperature": 0.7,            // Optional: Sampling temperature (0-2)
  "top_p": 1.0,                  // Optional: Nucleus sampling
  "tools": [...],                // Optional: Function calling tools
  "stream": true,                // Optional: Enable streaming (default: false)
  "metadata": {...},             // Optional: Custom metadata
  "store": false                 // Optional: Store response (not implemented)
}
```

**Input Formats:**

1. **Simple string:**
```json
{
  "input": "What is 2+2?"
}
```

2. **Structured messages:**
```json
{
  "input": [
    {
      "type": "message",
      "role": "user",
      "content": "What is 2+2?"
    }
  ]
}
```

3. **Multi-turn with content parts:**
```json
{
  "input": [
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "What is in this image?"
        },
        {
          "type": "input_image",
          "image_url": {
            "url": "data:image/jpeg;base64,..."
          }
        }
      ]
    }
  ]
}
```

**Response (Streaming):**

Server-sent events with the following event types:

1. **response.created** - Response started
```json
{
  "type": "response.created",
  "response": {
    "id": "resp_abc123",
    "object": "response",
    "created_at": 1234567890,
    "status": "in_progress",
    "model": "gpt-4o",
    "output": [],
    "usage": null
  },
  "sequence_number": 1
}
```

2. **response.output_item.added** - Output item added
```json
{
  "type": "response.output_item.added",
  "item_id": "msg_abc123",
  "output_index": 0,
  "item": {
    "id": "msg_abc123",
    "type": "message",
    "status": "in_progress",
    "role": "assistant",
    "content": []
  },
  "sequence_number": 2
}
```

3. **response.content_part.added** - Content part added
```json
{
  "type": "response.content_part.added",
  "item_id": "msg_abc123",
  "output_index": 0,
  "content_index": 0,
  "sequence_number": 3
}
```

4. **response.output_text.delta** - Text delta (multiple events)
```json
{
  "type": "response.output_text.delta",
  "item_id": "msg_abc123",
  "output_index": 0,
  "content_index": 0,
  "delta": "Hello",
  "sequence_number": 4
}
```

5. **response.output_text.done** - Text complete
```json
{
  "type": "response.output_text.done",
  "item_id": "msg_abc123",
  "output_index": 0,
  "content_index": 0,
  "text": "Hello there!",
  "sequence_number": 10
}
```

6. **response.content_part.done** - Content part done
```json
{
  "type": "response.content_part.done",
  "item_id": "msg_abc123",
  "output_index": 0,
  "content_index": 0,
  "sequence_number": 11
}
```

7. **response.output_item.done** - Output item done
```json
{
  "type": "response.output_item.done",
  "item_id": "msg_abc123",
  "output_index": 0,
  "item": {
    "id": "msg_abc123",
    "type": "message",
    "status": "completed",
    "role": "assistant",
    "content": [
      {
        "type": "output_text",
        "text": "Hello there!",
        "annotations": []
      }
    ]
  },
  "sequence_number": 12
}
```

8. **response.completed** - Response complete
```json
{
  "type": "response.completed",
  "response": {
    "id": "resp_abc123",
    "object": "response",
    "created_at": 1234567890,
    "status": "completed",
    "model": "gpt-4o",
    "output": [
      {
        "id": "msg_abc123",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [
          {
            "type": "output_text",
            "text": "Hello there!",
            "annotations": []
          }
        ]
      }
    ],
    "usage": {
      "input_tokens": 10,
      "output_tokens": 5,
      "total_tokens": 15,
      "input_tokens_details": {
        "cached_tokens": null
      },
      "output_tokens_details": {
        "reasoning_tokens": null
      }
    }
  },
  "sequence_number": 13
}
```

**Error Response:**

```json
{
  "type": "response.failed",
  "response": {
    "id": "resp_abc123",
    "status": "failed",
    "error": {
      "code": "backend_error",
      "message": "Error details..."
    }
  }
}
```

### GET /health

Health check endpoint with circuit breaker status.

**Response:**
```json
{
  "status": "healthy",
  "circuit_breaker": {
    "enabled": true,
    "is_open": false,
    "consecutive_failures": 0
  }
}
```

## Status Codes

- `200 OK` - Successful request
- `400 Bad Request` - Invalid request format
- `401 Unauthorized` - Missing or invalid API key
- `404 Not Found` - Model not found
- `503 Service Unavailable` - Circuit breaker open
- `502 Bad Gateway` - Backend connection failed

## Conversion Mapping

| Responses API | Chat Completions |
|---------------|------------------|
| `input` (string) | `messages[0].content` (user role) |
| `input` (array) | `messages` (mapped by role) |
| `instructions` | `messages[0]` (system role) |
| `max_output_tokens` | `max_tokens` |
| `temperature` | `temperature` |
| `top_p` | `top_p` |
| `tools` | `tools` |

**Event Mapping:**

| Chat Completions | Responses API |
|------------------|---------------|
| SSE chunk with `delta.content` | `response.output_text.delta` |
| `finish_reason: "stop"` | `status: "completed"` |
| `finish_reason: "length"` | `status: "incomplete"` |
| `error` object | `response.failed` |

## Limitations

- **Stateless only** - No conversation state storage
- **item_reference** - Not supported (logged and ignored)
- **store parameter** - Not implemented
- **Tool calls** - Basic support (needs enhancement for complex tools)
- **Image outputs** - Not supported (text only)

## Examples

See `tests/manual/` directory:
- `simple_request.sh` - Bash/curl example
- `python_client.py` - Python example
- `nodejs_client.js` - Node.js example
- `multi_turn.sh` - Multi-turn conversation
- `with_tools.sh` - Function calling example

## OpenAI Responses API Spec Compliance

## Summary

This document describes the compliance of the responses-proxy with the official OpenAI Responses API specification (`specs/openai-openapi.yml` v2.3.0, 66,009 lines).

**Last Updated:** November 4, 2025

---

## âœ… Implemented Features

### 1. **Complete Response Model Fields**

All required and optional fields from the official spec are now included in the `Response` object:

- `id`, `object`, `created_at`, `status` âœ…
- `error`, `incomplete_details` âœ…
- `model`, `output`, `usage`, `metadata` âœ…
- **Echo Parameters** (NEW): `instructions`, `tools`, `tool_choice`, `parallel_tool_calls`, `temperature`, `top_p`, `max_output_tokens` âœ…

### 2. **Tool Validation**

**Strict validation** now enforces that only `function` type tools are supported:

```rust
// In src/services/converter.rs
if tool.type_ != "function" {
    return Err(format!(
        "Unsupported tool type '{}'. Only 'function' tools are supported..."
    ));
}
```

**Why:** Chat Completions backends (like Chutes.ai) only support `function` tools. Advanced tools (`file_search`, `web_search`, `code_interpreter`, etc.) require native Responses API backends.

### 3. **Complete OutputItem Types**

Supports all output item types from the spec:

- `message` âœ…
- `function_call` âœ…
- `function_call_output` âœ… (with `output` field)
- `reasoning` âœ…
- `refusal` âœ…

### 4. **Complete OutputContent Types**

- `output_text` âœ…
- `reasoning` âœ…
- `refusal` âœ… (NEW)

### 5. **Incomplete Details**

Proper `incomplete_details` support with reason tracking:

```rust
incomplete_details: Some(IncompleteDetails {
    reason: "max_output_tokens" // or "content_filter"
})
```

### 6. **Streaming Events**

**Core Events Implemented (13):**

| Event Type | Status |
|------------|--------|
| `response.created` | âœ… |
| `response.output_item.added` | âœ… |
| `response.content_part.added` | âœ… |
| `response.output_text.delta` | âœ… |
| `response.output_text.done` | âœ… |
| `response.content_part.done` | âœ… |
| `response.output_item.done` | âœ… |
| `response.function_call_arguments.delta` | âœ… |
| `response.function_call_arguments.done` | âœ… |
| `response.reasoning_text.delta` | âœ… |
| `response.reasoning_text.done` | âœ… |
| `response.completed` | âœ… |
| `response.failed` | âœ… |

All events now properly include the `error` field (even when `None`).

---

## âš ï¸ Known Limitations (By Design)

### Unsupported Features (Due to Stateless Chat Completions Backend)

The following features from the full Responses API spec are **intentionally not supported** because they require:
1. Native Responses API backends (not Chat Completions)
2. Stateful storage (Redis/DB)
3. Advanced capabilities beyond function calling

**Advanced Tool Events (38 events):**
- âŒ Audio: `response.audio.*`
- âŒ Code Interpreter: `response.code_interpreter_call.*`
- âŒ File Search: `response.file_search_call.*`
- âŒ Web Search: `response.web_search_call.*`
- âŒ Image Gen: `response.image_gen_call.*`
- âŒ MCP (Model Context Protocol): `response.mcp_call.*`
- âŒ Custom Tools: `response.custom_tool_call.*`
- âŒ Reasoning Summary: `response.reasoning_summary.*`
- âŒ Other: `response.queued`, `response.in_progress`, `response.error` (during stream)

**Request Parameters:**
- âŒ `background` - async processing
- âŒ `previous_response_id` - stateful conversations
- âŒ `conversation` - conversation tracking
- âŒ `modalities` - audio/vision modes
- âŒ `audio` - audio configuration
- âŒ `truncation` - context truncation strategies
- âŒ `reasoning.effort` - o-series model control
- âŒ `include` - optional data inclusion

**Why These Limitations Exist:**

This proxy translates Responses API â†’ Chat Completions API â†’ Responses API for **stateless operation** with standard backends like:
- Chutes.ai
- OpenAI Chat Completions
- Azure OpenAI
- Any OpenAI-compatible API

These backends **only support**:
- Text generation
- Function calling
- Reasoning models (via `reasoning_content`)

They do **not support**:
- Advanced tool execution
- Stateful conversations
- Audio/multimodal responses

---

## ğŸ¯ What This Proxy Does Best

### âœ… Fully Supported Use Cases:

1. **Text Generation**
   - User messages â†’ Assistant responses
   - System instructions
   - Multi-turn conversations (via input history)
   - Streaming responses

2. **Function Calling**
   - Tool definitions
   - Tool calls from model
   - Tool results back to model
   - Parallel tool calls
   - Multi-turn function conversations

3. **Reasoning Models**
   - DeepSeek-R1, OpenAI o-series
   - Reasoning content extraction
   - `<think>` tag support
   - Reasoning items in output

4. **Request Echo**
   - All request parameters echoed back in response
   - Maintains request context for clients

---

## ğŸ“Š Compliance Matrix

### Request Parameters

| Parameter | Supported | Notes |
|-----------|-----------|-------|
| `model` | âœ… | Required |
| `input` | âœ… | String or array of items |
| `instructions` | âœ… | Maps to system message |
| `max_output_tokens` | âœ… | Mapped to `max_tokens` |
| `temperature` | âœ… | Pass-through |
| `top_p` | âœ… | Pass-through |
| `tools` | âš ï¸ | **Only `function` type** |
| `tool_choice` | âœ… | Pass-through |
| `parallel_tool_calls` | âœ… | Pass-through |
| `stream` | âœ… | SSE streaming |
| `metadata` | âœ… | Pass-through |
| `store` | âš ï¸ | Accepted but ignored (stateless) |
| `background` | âŒ | Not supported |
| `previous_response_id` | âŒ | Not supported (stateless) |
| `conversation` | âŒ | Not supported |
| `include` | âŒ | Not supported |
| `modalities` | âŒ | Not supported |
| `audio` | âŒ | Not supported |
| `truncation` | âŒ | Not supported |

### Response Fields

| Field | Supported | Notes |
|-------|-----------|-------|
| `id` | âœ… | Generated |
| `object` | âœ… | Always "response" |
| `created_at` | âœ… | Unix timestamp |
| `status` | âœ… | completed/failed/incomplete |
| `error` | âœ… | Error details |
| `incomplete_details` | âœ… | Reason for incomplete |
| `model` | âœ… | Echoed back |
| `output` | âœ… | Array of output items |
| `usage` | âœ… | Token counts |
| `metadata` | âœ… | Echoed back |
| `instructions` | âœ… | Echoed back |
| `tools` | âœ… | Echoed back |
| `tool_choice` | âœ… | Echoed back |
| `parallel_tool_calls` | âœ… | Echoed back |
| `temperature` | âœ… | Echoed back |
| `top_p` | âœ… | Echoed back |
| `max_output_tokens` | âœ… | Echoed back |

---

## ğŸ”§ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client             â”‚
â”‚  (Responses API)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ POST /responses
           â”‚ (Responses API format)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Responses Proxy    â”‚
â”‚  - Validate tools   â”‚
â”‚  - Convert request  â”‚
â”‚  - Map events       â”‚
â”‚  - Echo params      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ POST /chat/completions
           â”‚ (Chat Completions format)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend            â”‚
â”‚  - Chutes.ai        â”‚
â”‚  - OpenAI           â”‚
â”‚  - Azure OpenAI     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ SSE Stream
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Responses Proxy    â”‚
â”‚  - Parse chunks     â”‚
â”‚  - Generate events  â”‚
â”‚  - Track state      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ SSE Stream
           â”‚ (Responses API events)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client             â”‚
â”‚  (Receives events)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Error Messages

### Tool Validation Error

When a non-function tool is used:

```json
{
  "error": "Unsupported tool type 'file_search'. Only 'function' tools are supported when translating to Chat Completions API. Advanced tool types (file_search, web_search, code_interpreter, etc.) require native Responses API backends."
}
```

### Backend Error

When backend returns error:

```json
{
  "type": "response.failed",
  "response": {
    "status": "failed",
    "error": {
      "code": "backend_error",
      "message": "..."
    }
  }
}
```

---

## ğŸš€ Usage Example

```bash
curl https://api.yourserver.com/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $YOUR_API_KEY" \
  -d '{
    "model": "gpt-4",
    "input": "Tell me a joke",
    "instructions": "Be funny and concise",
    "tools": [{
      "type": "function",
      "function": {
        "name": "get_weather",
        "parameters": { "type": "object", "properties": {} }
      }
    }],
    "stream": true
  }'
```

**Response Stream:**

```
data: {"type":"response.created","response":{...,"instructions":"Be funny and concise","tools":[...]}}
data: {"type":"response.output_item.added",...}
data: {"type":"response.content_part.added",...}
data: {"type":"response.output_text.delta","delta":"Why"}
data: {"type":"response.output_text.delta","delta":" did"}
data: {"type":"response.output_text.done","text":"Why did..."}
data: {"type":"response.completed","response":{...}}
```

---

## ğŸ“š References

- **Official Spec**: `specs/openai-openapi.yml` (66,009 lines, OpenAPI 3.1.0)
- **Source**: https://app.stainless.com/api/spec/documented/openai/openapi.documented.yml
- **GitHub**: https://github.com/openai/openai-openapi
- **Docs**: https://platform.openai.com/docs/api-reference/responses

---

## âœ¨ Summary

This proxy provides **complete compliance** with the core Responses API for:
- âœ… Text generation
- âœ… Function calling
- âœ… Reasoning models
- âœ… Streaming events
- âœ… Parameter echo
- âœ… Error handling
- âœ… Tool validation

With clear **documented limitations** for features that require native Responses API backends or stateful storage.

**Perfect for:** Translating Responses API clients to work with any OpenAI-compatible Chat Completions backend.

