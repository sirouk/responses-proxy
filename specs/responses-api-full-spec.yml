  /responses:
    post:
      operationId: createResponse
      tags:
        - Responses
      summary: Create a model response
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateResponse'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ResponseStreamEvent'
      x-oaiMeta:
        name: Create a model response
        group: responses
        returns: |
          Returns a [Response](https://platform.openai.com/docs/api-reference/responses/object) object.
        path: create
        examples:
          - title: Text input
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "input": "Tell me a three sentence bedtime story about a unicorn."
                  }'
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    input: "Tell me a three sentence bedtime story about a unicorn."
                });

                console.log(response);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              csharp: >
                using System;

                using OpenAI.Responses;


                OpenAIResponseClient client = new(
                    model: "gpt-4.1",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );


                OpenAIResponse response = client.CreateResponse("Tell me a three sentence bedtime story about
                a unicorn.");


                Console.WriteLine(response.GetOutputText());
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
                "object": "response",
                "created_at": 1741476542,
                "status": "completed",
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "model": "gpt-4.1-2025-04-14",
                "output": [
                  {
                    "type": "message",
                    "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                      {
                        "type": "output_text",
                        "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
                        "annotations": []
                      }
                    ]
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": null,
                  "summary": null
                },
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [],
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 36,
                  "input_tokens_details": {
                    "cached_tokens": 0
                  },
                  "output_tokens": 87,
                  "output_tokens_details": {
                    "reasoning_tokens": 0
                  },
                  "total_tokens": 123
                },
                "user": null,
                "metadata": {}
              }
          - title: Image input
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "input": [
                      {
                        "role": "user",
                        "content": [
                          {"type": "input_text", "text": "what is in this image?"},
                          {
                            "type": "input_image",
                            "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        ]
                      }
                    ]
                  }'
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    input: [
                        {
                            role: "user",
                            content: [
                                { type: "input_text", text: "what is in this image?" },
                                {
                                    type: "input_image",
                                    image_url:
                                        "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                                },
                            ],
                        },
                    ],
                });

                console.log(response);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              csharp: |
                using System;
                using System.Collections.Generic;

                using OpenAI.Responses;

                OpenAIResponseClient client = new(
                    model: "gpt-4.1",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                List<ResponseItem> inputItems =
                [
                    ResponseItem.CreateUserMessageItem(
                        [
                            ResponseContentPart.CreateInputTextPart("What is in this image?"),
                            ResponseContentPart.CreateInputImagePart(new Uri("https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"))
                        ]
                    )
                ];

                OpenAIResponse response = client.CreateResponse(inputItems);

                Console.WriteLine(response.GetOutputText());
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
                "object": "response",
                "created_at": 1741476777,
                "status": "completed",
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "model": "gpt-4.1-2025-04-14",
                "output": [
                  {
                    "type": "message",
                    "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                      {
                        "type": "output_text",
                        "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
                        "annotations": []
                      }
                    ]
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": null,
                  "summary": null
                },
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [],
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 328,
                  "input_tokens_details": {
                    "cached_tokens": 0
                  },
                  "output_tokens": 52,
                  "output_tokens_details": {
                    "reasoning_tokens": 0
                  },
                  "total_tokens": 380
                },
                "user": null,
                "metadata": {}
              }
          - title: File input
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "input": [
                      {
                        "role": "user",
                        "content": [
                          {"type": "input_text", "text": "what is in this file?"},
                          {
                            "type": "input_file",
                            "file_url": "https://www.berkshirehathaway.com/letters/2024ltr.pdf"
                          }
                        ]
                      }
                    ]
                  }'
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    input: [
                        {
                            role: "user",
                            content: [
                                { type: "input_text", text: "what is in this file?" },
                                {
                                    type: "input_file",
                                    file_url: "https://www.berkshirehathaway.com/letters/2024ltr.pdf",
                                },
                            ],
                        },
                    ],
                });

                console.log(response);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_686eef60237881a2bd1180bb8b13de430e34c516d176ff86",
                "object": "response",
                "created_at": 1752100704,
                "status": "completed",
                "background": false,
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "max_tool_calls": null,
                "model": "gpt-4.1-2025-04-14",
                "output": [
                  {
                    "id": "msg_686eef60d3e081a29283bdcbc4322fd90e34c516d176ff86",
                    "type": "message",
                    "status": "completed",
                    "content": [
                      {
                        "type": "output_text",
                        "annotations": [],
                        "logprobs": [],
                        "text": "The file seems to contain excerpts from a letter to the shareholders of Berkshire Hathaway Inc., likely written by Warren Buffett. It covers several topics:\n\n1. **Communication Philosophy**: Buffett emphasizes the importance of transparency and candidness in reporting mistakes and successes to shareholders.\n\n2. **Mistakes and Learnings**: The letter acknowledges past mistakes in business assessments and management hires, highlighting the importance of correcting errors promptly.\n\n3. **CEO Succession**: Mention of Greg Abel stepping in as the new CEO and continuing the tradition of honest communication.\n\n4. **Pete Liegl Story**: A detailed account of acquiring Forest River and the relationship with its founder, highlighting trust and effective business decisions.\n\n5. **2024 Performance**: Overview of business performance, particularly in insurance and investment activities, with a focus on GEICO's improvement.\n\n6. **Tax Contributions**: Discussion of significant tax payments to the U.S. Treasury, credited to shareholders' reinvestments.\n\n7. **Investment Strategy**: A breakdown of Berkshire\u2019s investments in both controlled subsidiaries and marketable equities, along with a focus on long-term holding strategies.\n\n8. **American Capitalism**: Reflections on America\u2019s economic development and Berkshire\u2019s role within it.\n\n9. **Property-Casualty Insurance**: Insights into the P/C insurance business model and its challenges and benefits.\n\n10. **Japanese Investments**: Information about Berkshire\u2019s investments in Japanese companies and future plans.\n\n11. **Annual Meeting**: Details about the upcoming annual gathering in Omaha, including schedule changes and new book releases.\n\n12. **Personal Anecdotes**: Light-hearted stories about family and interactions, conveying Buffett's personable approach.\n\n13. **Financial Performance Data**: Tables comparing Berkshire\u2019s annual performance to the S&P 500, showing impressive long-term gains.\n\nOverall, the letter reinforces Berkshire Hathaway's commitment to transparency, investment in both its businesses and the wider economy, and emphasizes strong leadership and prudent financial management."
                      }
                    ],
                    "role": "assistant"
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": null,
                  "summary": null
                },
                "service_tier": "default",
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [],
                "top_logprobs": 0,
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 8438,
                  "input_tokens_details": {
                    "cached_tokens": 0
                  },
                  "output_tokens": 398,
                  "output_tokens_details": {
                    "reasoning_tokens": 0
                  },
                  "total_tokens": 8836
                },
                "user": null,
                "metadata": {}
              }
          - title: Web search
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "tools": [{ "type": "web_search_preview" }],
                    "input": "What was a positive news story from today?"
                  }'
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    tools: [{ type: "web_search_preview" }],
                    input: "What was a positive news story from today?",
                });

                console.log(response);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              csharp: |
                using System;

                using OpenAI.Responses;

                OpenAIResponseClient client = new(
                    model: "gpt-4.1",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                string userInputText = "What was a positive news story from today?";

                ResponseCreationOptions options = new()
                {
                    Tools =
                    {
                        ResponseTool.CreateWebSearchTool()
                    },
                };

                OpenAIResponse response = client.CreateResponse(userInputText, options);

                Console.WriteLine(response.GetOutputText());
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c",
                "object": "response",
                "created_at": 1741484430,
                "status": "completed",
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "model": "gpt-4.1-2025-04-14",
                "output": [
                  {
                    "type": "web_search_call",
                    "id": "ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c",
                    "status": "completed"
                  },
                  {
                    "type": "message",
                    "id": "msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                      {
                        "type": "output_text",
                        "text": "As of today, March 9, 2025, one notable positive news story...",
                        "annotations": [
                          {
                            "type": "url_citation",
                            "start_index": 442,
                            "end_index": 557,
                            "url": "https://.../?utm_source=chatgpt.com",
                            "title": "..."
                          },
                          {
                            "type": "url_citation",
                            "start_index": 962,
                            "end_index": 1077,
                            "url": "https://.../?utm_source=chatgpt.com",
                            "title": "..."
                          },
                          {
                            "type": "url_citation",
                            "start_index": 1336,
                            "end_index": 1451,
                            "url": "https://.../?utm_source=chatgpt.com",
                            "title": "..."
                          }
                        ]
                      }
                    ]
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": null,
                  "summary": null
                },
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [
                  {
                    "type": "web_search_preview",
                    "domains": [],
                    "search_context_size": "medium",
                    "user_location": {
                      "type": "approximate",
                      "city": null,
                      "country": "US",
                      "region": null,
                      "timezone": null
                    }
                  }
                ],
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 328,
                  "input_tokens_details": {
                    "cached_tokens": 0
                  },
                  "output_tokens": 356,
                  "output_tokens_details": {
                    "reasoning_tokens": 0
                  },
                  "total_tokens": 684
                },
                "user": null,
                "metadata": {}
              }
          - title: File search
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "tools": [{
                      "type": "file_search",
                      "vector_store_ids": ["vs_1234567890"],
                      "max_num_results": 20
                    }],
                    "input": "What are the attributes of an ancient brown dragon?"
                  }'
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    tools: [{
                      type: "file_search",
                      vector_store_ids: ["vs_1234567890"],
                      max_num_results: 20
                    }],
                    input: "What are the attributes of an ancient brown dragon?",
                });

                console.log(response);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              csharp: |
                using System;

                using OpenAI.Responses;

                OpenAIResponseClient client = new(
                    model: "gpt-4.1",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                string userInputText = "What are the attributes of an ancient brown dragon?";

                ResponseCreationOptions options = new()
                {
                    Tools =
                    {
                        ResponseTool.CreateFileSearchTool(
                            vectorStoreIds: ["vs_1234567890"],
                            maxResultCount: 20
                        )
                    },
                };

                OpenAIResponse response = client.CreateResponse(userInputText, options);

                Console.WriteLine(response.GetOutputText());
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7",
                "object": "response",
                "created_at": 1741485253,
                "status": "completed",
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "model": "gpt-4.1-2025-04-14",
                "output": [
                  {
                    "type": "file_search_call",
                    "id": "fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7",
                    "status": "completed",
                    "queries": [
                      "attributes of an ancient brown dragon"
                    ],
                    "results": null
                  },
                  {
                    "type": "message",
                    "id": "msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                      {
                        "type": "output_text",
                        "text": "The attributes of an ancient brown dragon include...",
                        "annotations": [
                          {
                            "type": "file_citation",
                            "index": 320,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 576,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 815,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 815,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 1030,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 1030,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 1156,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          },
                          {
                            "type": "file_citation",
                            "index": 1225,
                            "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                            "filename": "dragons.pdf"
                          }
                        ]
                      }
                    ]
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": null,
                  "summary": null
                },
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [
                  {
                    "type": "file_search",
                    "filters": null,
                    "max_num_results": 20,
                    "ranking_options": {
                      "ranker": "auto",
                      "score_threshold": 0.0
                    },
                    "vector_store_ids": [
                      "vs_1234567890"
                    ]
                  }
                ],
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 18307,
                  "input_tokens_details": {
                    "cached_tokens": 0
                  },
                  "output_tokens": 348,
                  "output_tokens_details": {
                    "reasoning_tokens": 0
                  },
                  "total_tokens": 18655
                },
                "user": null,
                "metadata": {}
              }      
          - title: Streaming
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "instructions": "You are a helpful assistant.",
                    "input": "Hello!",
                    "stream": true
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    instructions: "You are a helpful assistant.",
                    input: "Hello!",
                    stream: true,
                });

                for await (const event of response) {
                    console.log(event);
                }
              csharp: >
                using System;

                using System.ClientModel;

                using System.Threading.Tasks;


                using OpenAI.Responses;


                OpenAIResponseClient client = new(
                    model: "gpt-4.1",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );


                string userInputText = "Hello!";


                ResponseCreationOptions options = new()

                {
                    Instructions = "You are a helpful assistant.",
                };


                AsyncCollectionResult<StreamingResponseUpdate> responseUpdates =
                client.CreateResponseStreamingAsync(userInputText, options);


                await foreach (StreamingResponseUpdate responseUpdate in responseUpdates)

                {
                    if (responseUpdate is StreamingResponseOutputTextDeltaUpdate outputTextDeltaUpdate)
                    {
                        Console.Write(outputTextDeltaUpdate.Delta);
                    }
                }
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: >
              event: response.created

              data:
              {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You
              are a helpful
              assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}


              event: response.in_progress

              data:
              {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You
              are a helpful
              assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}


              event: response.output_item.added

              data:
              {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}


              event: response.content_part.added

              data:
              {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}


              event: response.output_text.delta

              data:
              {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"Hi"}


              ...


              event: response.output_text.done

              data:
              {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"Hi
              there! How can I assist you today?"}


              event: response.content_part.done

              data:
              {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"Hi
              there! How can I assist you today?","annotations":[]}}


              event: response.output_item.done

              data:
              {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi
              there! How can I assist you today?","annotations":[]}]}}


              event: response.completed

              data:
              {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"You
              are a helpful
              assistant.","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi
              there! How can I assist you
              today?","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}
          - title: Functions
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4.1",
                    "input": "What is the weather like in Boston today?",
                    "tools": [
                      {
                        "type": "function",
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location", "unit"]
                        }
                      }
                    ],
                    "tool_choice": "auto"
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              javascript: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const tools = [
                    {
                        type: "function",
                        name: "get_current_weather",
                        description: "Get the current weather in a given location",
                        parameters: {
                            type: "object",
                            properties: {
                                location: {
                                    type: "string",
                                    description: "The city and state, e.g. San Francisco, CA",
                                },
                                unit: { type: "string", enum: ["celsius", "fahrenheit"] },
                            },
                            required: ["location", "unit"],
                        },
                    },
                ];

                const response = await openai.responses.create({
                    model: "gpt-4.1",
                    tools: tools,
                    input: "What is the weather like in Boston today?",
                    tool_choice: "auto",
                });

                console.log(response);
              csharp: |
                using System;
                using OpenAI.Responses;

                OpenAIResponseClient client = new(
                    model: "gpt-4.1",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                ResponseTool getCurrentWeatherFunctionTool = ResponseTool.CreateFunctionTool(
                    functionName: "get_current_weather",
                    functionDescription: "Get the current weather in a given location",
                    functionParameters: BinaryData.FromString("""
                        {
                            "type": "object",
                            "properties": {
                                "location": {
                                    "type": "string",
                                    "description": "The city and state, e.g. San Francisco, CA"
                                },
                                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                            },
                            "required": ["location", "unit"]
                        }
                        """
                    )
                );

                string userInputText = "What is the weather like in Boston today?";

                ResponseCreationOptions options = new()
                {
                    Tools =
                    {
                        getCurrentWeatherFunctionTool
                    },
                    ToolChoice = ResponseToolChoice.CreateAutoChoice(),
                };

                OpenAIResponse response = client.CreateResponse(userInputText, options);
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0",
                "object": "response",
                "created_at": 1741294021,
                "status": "completed",
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "model": "gpt-4.1-2025-04-14",
                "output": [
                  {
                    "type": "function_call",
                    "id": "fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0",
                    "call_id": "call_unLAR8MvFNptuiZK6K6HCy5k",
                    "name": "get_current_weather",
                    "arguments": "{\"location\":\"Boston, MA\",\"unit\":\"celsius\"}",
                    "status": "completed"
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": null,
                  "summary": null
                },
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [
                  {
                    "type": "function",
                    "description": "Get the current weather in a given location",
                    "name": "get_current_weather",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": [
                            "celsius",
                            "fahrenheit"
                          ]
                        }
                      },
                      "required": [
                        "location",
                        "unit"
                      ]
                    },
                    "strict": true
                  }
                ],
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 291,
                  "output_tokens": 23,
                  "output_tokens_details": {
                    "reasoning_tokens": 0
                  },
                  "total_tokens": 314
                },
                "user": null,
                "metadata": {}
              }
          - title: Reasoning
            request:
              curl: |
                curl https://api.openai.com/v1/responses \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "o3-mini",
                    "input": "How much wood would a woodchuck chuck?",
                    "reasoning": {
                      "effort": "high"
                    }
                  }'
              javascript: |
                import OpenAI from "openai";
                const openai = new OpenAI();

                const response = await openai.responses.create({
                    model: "o3-mini",
                    input: "How much wood would a woodchuck chuck?",
                    reasoning: {
                      effort: "high"
                    }
                });

                console.log(response);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                response = client.responses.create()
                print(response.id)
              csharp: |
                using System;
                using OpenAI.Responses;

                OpenAIResponseClient client = new(
                    model: "o3-mini",
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                string userInputText = "How much wood would a woodchuck chuck?";

                ResponseCreationOptions options = new()
                {
                    ReasoningOptions = new()
                    {
                        ReasoningEffortLevel = ResponseReasoningEffortLevel.High,
                    },
                };

                OpenAIResponse response = client.CreateResponse(userInputText, options);

                Console.WriteLine(response.GetOutputText());
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const response = await client.responses.create();

                console.log(response.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/responses"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  response, err := client.Responses.New(context.TODO(), responses.ResponseNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", response.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.responses.Response;
                import com.openai.models.responses.ResponseCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Response response = client.responses().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                response = openai.responses.create

                puts(response)
            response: |
              {
                "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
                "object": "response",
                "created_at": 1741477868,
                "status": "completed",
                "error": null,
                "incomplete_details": null,
                "instructions": null,
                "max_output_tokens": null,
                "model": "o1-2024-12-17",
                "output": [
                  {
                    "type": "message",
                    "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
                    "status": "completed",
                    "role": "assistant",
                    "content": [
                      {
                        "type": "output_text",
                        "text": "The classic tongue twister...",
                        "annotations": []
                      }
                    ]
                  }
                ],
                "parallel_tool_calls": true,
                "previous_response_id": null,
                "reasoning": {
                  "effort": "high",
                  "summary": null
                },
                "store": true,
                "temperature": 1.0,
                "text": {
                  "format": {
                    "type": "text"
                  }
                },
                "tool_choice": "auto",
                "tools": [],
                "top_p": 1.0,
                "truncation": "disabled",
                "usage": {
                  "input_tokens": 81,
                  "input_tokens_details": {
                    "cached_tokens": 0
                  },
                  "output_tokens": 1035,
                  "output_tokens_details": {
                    "reasoning_tokens": 832
                  },
                  "total_tokens": 1116
                },
                "user": null,
                "metadata": {}
              }
      description: >
        Creates a model response. Provide [text](https://platform.openai.com/docs/guides/text) or

        [image](https://platform.openai.com/docs/guides/images) inputs to generate
        [text](https://platform.openai.com/docs/guides/text)

        or [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have the model call

        your own [custom code](https://platform.openai.com/docs/guides/function-calling) or use built-in

        [tools](https://platform.openai.com/docs/guides/tools) like [web
        search](https://platform.openai.com/docs/guides/tools-web-search)

        or [file search](https://platform.openai.com/docs/guides/tools-file-search) to use your own data

        as input for the model's response.
  /responses/{response_id}:
    get:
      operationId: getResponse
      tags:
        - Responses
      summary: Get a model response
      parameters:
        - in: path
          name: response_id
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
          description: The ID of the response to retrieve.
        - in: query
          name: include
          schema:
            type: array
            items:
              $ref: '#/components/schemas/IncludeEnum'
          description: |
            Additional fields to include in the response. See the `include`
            parameter for Response creation above for more information.
        - in: query
          name: stream
          schema:
            type: boolean
          description: >
            If set to true, the model response data will be streamed to the client

            as it is generated using [server-sent
            events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).

            See the [Streaming section
            below](https://platform.openai.com/docs/api-reference/responses-streaming)

            for more information.
        - in: query
          name: starting_after
          schema:
            type: integer
          description: |
            The sequence number of the event after which to start streaming.
        - in: query
          name: include_obfuscation
          schema:
            type: boolean
          description: |
            When true, stream obfuscation will be enabled. Stream obfuscation adds
            random characters to an `obfuscation` field on streaming delta events
            to normalize payload sizes as a mitigation to certain side-channel
            attacks. These obfuscation fields are included by default, but add a
            small amount of overhead to the data stream. You can set
            `include_obfuscation` to false to optimize for bandwidth if you trust
            the network links between your application and the OpenAI API.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
      x-oaiMeta:
        name: Get a model response
        group: responses
        returns: |
          The [Response](https://platform.openai.com/docs/api-reference/responses/object) object matching the
          specified ID.
        examples:
          response: |
            {
              "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
              "object": "response",
              "created_at": 1741386163,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "Silent circuits hum,  \nThoughts emerge in data streams  \nDigital dawn breaks.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 32,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 18,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 50
              },
              "user": null,
              "metadata": {}
            }
          request:
            curl: |
              curl https://api.openai.com/v1/responses/resp_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: |
              import OpenAI from "openai";
              const client = new OpenAI();

              const response = await client.responses.retrieve("resp_123");
              console.log(response);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              response = client.responses.retrieve(
                  response_id="resp_677efb5139a88190b512bc3fef8e535d",
              )
              print(response.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const response = await client.responses.retrieve('resp_677efb5139a88190b512bc3fef8e535d');

              console.log(response.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
                "github.com/openai/openai-go/responses"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                response, err := client.Responses.Get(
                  context.TODO(),
                  "resp_677efb5139a88190b512bc3fef8e535d",
                  responses.ResponseGetParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", response.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.responses.Response;
              import com.openai.models.responses.ResponseRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      Response response = client.responses().retrieve("resp_677efb5139a88190b512bc3fef8e535d");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              response = openai.responses.retrieve("resp_677efb5139a88190b512bc3fef8e535d")

              puts(response)
      description: |
        Retrieves a model response with the given ID.
    delete:
      operationId: deleteResponse
      tags:
        - Responses
      summary: Delete a model response
      parameters:
        - in: path
          name: response_id
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
          description: The ID of the response to delete.
      responses:
        '200':
          description: OK
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        name: Delete a model response
        group: responses
        returns: |
          A success message.
        examples:
          response: |
            {
              "id": "resp_6786a1bec27481909a17d673315b29f6",
              "object": "response",
              "deleted": true
            }
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/responses/resp_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: |
              import OpenAI from "openai";
              const client = new OpenAI();

              const response = await client.responses.delete("resp_123");
              console.log(response);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              client.responses.delete(
                  "resp_677efb5139a88190b512bc3fef8e535d",
              )
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              await client.responses.delete('resp_677efb5139a88190b512bc3fef8e535d');
            go: |
              package main

              import (
                "context"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                err := client.Responses.Delete(context.TODO(), "resp_677efb5139a88190b512bc3fef8e535d")
                if err != nil {
                  panic(err.Error())
                }
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.responses.ResponseDeleteParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      client.responses().delete("resp_677efb5139a88190b512bc3fef8e535d");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              result = openai.responses.delete("resp_677efb5139a88190b512bc3fef8e535d")

              puts(result)
      description: |
        Deletes a model response with the given ID.
  /responses/{response_id}/cancel:
    post:
      operationId: cancelResponse
      tags:
        - Responses
      summary: Cancel a response
      parameters:
        - in: path
          name: response_id
          required: true
          schema:
            type: string
            example: resp_677efb5139a88190b512bc3fef8e535d
          description: The ID of the response to cancel.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
      x-oaiMeta:
        name: Cancel a response
        group: responses
        returns: |
          A [Response](https://platform.openai.com/docs/api-reference/responses/object) object.
        examples:
          response: |
            {
              "id": "resp_67cb71b351908190a308f3859487620d06981a8637e6bc44",
              "object": "response",
              "created_at": 1741386163,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67cb71b3c2b0819084d481baaaf148f206981a8637e6bc44",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "Silent circuits hum,  \nThoughts emerge in data streams  \nDigital dawn breaks.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 32,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 18,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 50
              },
              "user": null,
              "metadata": {}
            }
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/responses/resp_123/cancel \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: |
              import OpenAI from "openai";
              const client = new OpenAI();

              const response = await client.responses.cancel("resp_123");
              console.log(response);  
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              response = client.responses.cancel(
                  "resp_677efb5139a88190b512bc3fef8e535d",
              )
              print(response.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const response = await client.responses.cancel('resp_677efb5139a88190b512bc3fef8e535d');

              console.log(response.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                response, err := client.Responses.Cancel(context.TODO(), "resp_677efb5139a88190b512bc3fef8e535d")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", response.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.responses.Response;
              import com.openai.models.responses.ResponseCancelParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      Response response = client.responses().cancel("resp_677efb5139a88190b512bc3fef8e535d");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              response = openai.responses.cancel("resp_677efb5139a88190b512bc3fef8e535d")

              puts(response)
      description: |
        Cancels a model response with the given ID. Only responses created with
        the `background` parameter set to `true` can be cancelled. 
        [Learn more](https://platform.openai.com/docs/guides/background).
  /responses/{response_id}/input_items:
    get:
      operationId: listInputItems
      tags:
        - Responses
      summary: List input items
      parameters:
        - in: path
          name: response_id
          required: true
          schema:
            type: string
          description: The ID of the response to retrieve input items for.
        - name: limit
          in: query
          description: |
            A limit on the number of objects to be returned. Limit can range between
            1 and 100, and the default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - in: query
          name: order
          schema:
            type: string
            enum:
              - asc
              - desc
          description: |
            The order to return the input items in. Default is `desc`.
            - `asc`: Return the input items in ascending order.
            - `desc`: Return the input items in descending order.
        - in: query
          name: after
          schema:
            type: string
          description: |
            An item ID to list items after, used in pagination.
        - in: query
          name: include
          schema:
            type: array
            items:
              $ref: '#/components/schemas/IncludeEnum'
          description: |
            Additional fields to include in the response. See the `include`
            parameter for Response creation above for more information.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ResponseItemList'
      x-oaiMeta:
        name: List input items
        group: responses
        returns: A list of input item objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "type": "message",
                  "role": "user",
                  "content": [
                    {
                      "type": "input_text",
                      "text": "Tell me a three sentence bedtime story about a unicorn."
                    }
                  ]
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc123",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/responses/resp_abc123/input_items \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            javascript: |
              import OpenAI from "openai";
              const client = new OpenAI();

              const response = await client.responses.inputItems.list("resp_123");
              console.log(response.data);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.responses.input_items.list(
                  response_id="response_id",
              )
              page = page.data[0]
              print(page)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const responseItem of client.responses.inputItems.list('response_id')) {
                console.log(responseItem);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
                "github.com/openai/openai-go/responses"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.Responses.InputItems.List(
                  context.TODO(),
                  "response_id",
                  responses.InputItemListParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.responses.inputitems.InputItemListPage;
              import com.openai.models.responses.inputitems.InputItemListParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      InputItemListPage page = client.responses().inputItems().list("response_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.responses.input_items.list("response_id")

              puts(page)
      description: Returns a list of input items for a given response.
  /threads:
    post:
      operationId: createThread
      tags:
        - Assistants
      summary: Create thread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Create thread
        group: threads
        beta: true
        returns: A [thread](https://platform.openai.com/docs/api-reference/threads) object.
        examples:
          - title: Empty
            request:
              curl: |
                curl https://api.openai.com/v1/threads \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d ''
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                thread = client.beta.threads.create()
                print(thread.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const thread = await client.beta.threads.create();

                console.log(thread.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  thread, err := client.Beta.Threads.New(context.TODO(), openai.BetaThreadNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", thread.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.Thread;
                import com.openai.models.beta.threads.ThreadCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Thread thread = client.beta().threads().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                thread = openai.beta.threads.create

                puts(thread)
            response: |
              {
                "id": "thread_abc123",
                "object": "thread",
                "created_at": 1699012949,
                "metadata": {},
                "tool_resources": {}
              }
          - title: Messages
            request:
              curl: |
                curl https://api.openai.com/v1/threads \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "messages": [{
                      "role": "user",
                      "content": "Hello, what is AI?"
                    }, {
                      "role": "user",
                      "content": "How does AI work? Explain it in simple terms."
                    }]
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                thread = client.beta.threads.create()
                print(thread.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const thread = await client.beta.threads.create();

                console.log(thread.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  thread, err := client.Beta.Threads.New(context.TODO(), openai.BetaThreadNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", thread.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.Thread;
                import com.openai.models.beta.threads.ThreadCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Thread thread = client.beta().threads().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                thread = openai.beta.threads.create

                puts(thread)
            response: |
              {
                "id": "thread_abc123",
                "object": "thread",
                "created_at": 1699014083,
                "metadata": {},
                "tool_resources": {}
              }
      description: Create a thread.
  /threads/runs:
    post:
      operationId: createThreadAndRun
      tags:
        - Assistants
      summary: Create thread and run
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create thread and run
        group: threads
        beta: true
        returns: A [run](https://platform.openai.com/docs/api-reference/runs/object) object.
        examples:
          - title: Default
            request:
              curl: |
                curl https://api.openai.com/v1/threads/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                      "assistant_id": "asst_abc123",
                      "thread": {
                        "messages": [
                          {"role": "user", "content": "Explain deep learning to a 5 year old."}
                        ]
                      }
                    }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.create_and_run(
                    assistant_id="assistant_id",
                )
                print(run.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const run = await client.beta.threads.createAndRun({ assistant_id: 'assistant_id' });

                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.NewAndRun(context.TODO(), openai.BetaThreadNewAndRunParams{
                    AssistantID: "assistant_id",
                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.ThreadCreateAndRunParams;
                import com.openai.models.beta.threads.runs.Run;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        ThreadCreateAndRunParams params = ThreadCreateAndRunParams.builder()
                            .assistantId("assistant_id")
                            .build();
                        Run run = client.beta().threads().createAndRun(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                run = openai.beta.threads.create_and_run(assistant_id: "assistant_id")

                puts(run)
            response: |
              {
                "id": "run_abc123",
                "object": "thread.run",
                "created_at": 1699076792,
                "assistant_id": "asst_abc123",
                "thread_id": "thread_abc123",
                "status": "queued",
                "started_at": null,
                "expires_at": 1699077392,
                "cancelled_at": null,
                "failed_at": null,
                "completed_at": null,
                "required_action": null,
                "last_error": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant.",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "temperature": 1.0,
                "top_p": 1.0,
                "max_completion_tokens": null,
                "max_prompt_tokens": null,
                "truncation_strategy": {
                  "type": "auto",
                  "last_messages": null
                },
                "incomplete_details": null,
                "usage": null,
                "response_format": "auto",
                "tool_choice": "auto",
                "parallel_tool_calls": true
              }
          - title: Streaming
            request:
              curl: |
                curl https://api.openai.com/v1/threads/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "Hello"}
                      ]
                    },
                    "stream": true
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.create_and_run(
                    assistant_id="assistant_id",
                )
                print(run.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const run = await client.beta.threads.createAndRun({ assistant_id: 'assistant_id' });

                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.NewAndRun(context.TODO(), openai.BetaThreadNewAndRunParams{
                    AssistantID: "assistant_id",
                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.ThreadCreateAndRunParams;
                import com.openai.models.beta.threads.runs.Run;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        ThreadCreateAndRunParams params = ThreadCreateAndRunParams.builder()
                            .assistantId("assistant_id")
                            .build();
                        Run run = client.beta().threads().createAndRun(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                run = openai.beta.threads.create_and_run(assistant_id: "assistant_id")

                puts(run)
            response: >
              event: thread.created

              data: {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}


              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],
              "metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],
              "metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              today"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
              How can I assist you today?","annotations":[]}}], "metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


              event: thread.run.completed

              {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


              event: done

              data: [DONE]
          - title: Streaming with Functions
            request:
              curl: |
                curl https://api.openai.com/v1/threads/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_abc123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "What is the weather like in San Francisco?"}
                      ]
                    },
                    "tools": [
                      {
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "description": "Get the current weather in a given location",
                          "parameters": {
                            "type": "object",
                            "properties": {
                              "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                "type": "string",
                                "enum": ["celsius", "fahrenheit"]
                              }
                            },
                            "required": ["location"]
                          }
                        }
                      }
                    ],
                    "stream": true
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.create_and_run(
                    assistant_id="assistant_id",
                )
                print(run.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const run = await client.beta.threads.createAndRun({ assistant_id: 'assistant_id' });

                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.NewAndRun(context.TODO(), openai.BetaThreadNewAndRunParams{
                    AssistantID: "assistant_id",
                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.ThreadCreateAndRunParams;
                import com.openai.models.beta.threads.runs.Run;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        ThreadCreateAndRunParams params = ThreadCreateAndRunParams.builder()
                            .assistantId("assistant_id")
                            .build();
                        Run run = client.beta().threads().createAndRun(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                run = openai.beta.threads.create_and_run(assistant_id: "assistant_id")

                puts(run)
            response: >
              event: thread.created

              data: {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}


              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}


              ...


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}


              event: thread.run.requires_action

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San
              Francisco,
              CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: done

              data: [DONE]
      description: Create a thread and run it in one request.
  /threads/{thread_id}:
    get:
      operationId: getThread
      tags:
        - Assistants
      summary: Retrieve thread
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to retrieve.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Retrieve thread
        group: threads
        beta: true
        returns: >-
          The [thread](https://platform.openai.com/docs/api-reference/threads/object) object matching the
          specified ID.
        examples:
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": []
                }
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              thread = client.beta.threads.retrieve(
                  "thread_id",
              )
              print(thread.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const thread = await client.beta.threads.retrieve('thread_id');

              console.log(thread.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                thread, err := client.Beta.Threads.Get(context.TODO(), "thread_id")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", thread.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.Thread;
              import com.openai.models.beta.threads.ThreadRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      Thread thread = client.beta().threads().retrieve("thread_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              thread = openai.beta.threads.retrieve("thread_id")

              puts(thread)
      description: Retrieves a thread.
    post:
      operationId: modifyThread
      tags:
        - Assistants
      summary: Modify thread
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to modify. Only the `metadata` can be modified.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Modify thread
        group: threads
        beta: true
        returns: >-
          The modified [thread](https://platform.openai.com/docs/api-reference/threads/object) object matching
          the specified ID.
        examples:
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {
                "modified": "true",
                "user": "abc123"
              },
              "tool_resources": {}
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              thread = client.beta.threads.update(
                  thread_id="thread_id",
              )
              print(thread.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const thread = await client.beta.threads.update('thread_id');

              console.log(thread.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                thread, err := client.Beta.Threads.Update(
                  context.TODO(),
                  "thread_id",
                  openai.BetaThreadUpdateParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", thread.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.Thread;
              import com.openai.models.beta.threads.ThreadUpdateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      Thread thread = client.beta().threads().update("thread_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              thread = openai.beta.threads.update("thread_id")

              puts(thread)
      description: Modifies a thread.
    delete:
      operationId: deleteThread
      tags:
        - Assistants
      summary: Delete thread
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to delete.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
      x-oaiMeta:
        name: Delete thread
        group: threads
        beta: true
        returns: Deletion status
        examples:
          response: |
            {
              "id": "thread_abc123",
              "object": "thread.deleted",
              "deleted": true
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              thread_deleted = client.beta.threads.delete(
                  "thread_id",
              )
              print(thread_deleted.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const threadDeleted = await client.beta.threads.delete('thread_id');

              console.log(threadDeleted.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                threadDeleted, err := client.Beta.Threads.Delete(context.TODO(), "thread_id")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", threadDeleted.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.ThreadDeleteParams;
              import com.openai.models.beta.threads.ThreadDeleted;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      ThreadDeleted threadDeleted = client.beta().threads().delete("thread_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              thread_deleted = openai.beta.threads.delete("thread_id")

              puts(thread_deleted)
      description: Delete a thread.
  /threads/{thread_id}/messages:
    get:
      operationId: listMessages
      tags:
        - Assistants
      summary: List messages
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: >-
            The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) the messages belong
            to.
        - name: limit
          in: query
          description: >
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for
            descending order.
          schema:
            type: string
            default: desc
            enum:
              - asc
              - desc
        - name: after
          in: query
          description: >
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent
            call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: >
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, starting with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
        - name: run_id
          in: query
          description: |
            Filter messages by the run ID that generated them.
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
      x-oaiMeta:
        name: List messages
        group: threads
        beta: true
        returns: A list of [message](https://platform.openai.com/docs/api-reference/messages) objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "How does AI work? Explain it in simple terms.",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                },
                {
                  "id": "msg_abc456",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "Hello, what is AI?",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc456",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.beta.threads.messages.list(
                  thread_id="thread_id",
              )
              page = page.data[0]
              print(page.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const message of client.beta.threads.messages.list('thread_id')) {
                console.log(message.id);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.Beta.Threads.Messages.List(
                  context.TODO(),
                  "thread_id",
                  openai.BetaThreadMessageListParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.messages.MessageListPage;
              import com.openai.models.beta.threads.messages.MessageListParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      MessageListPage page = client.beta().threads().messages().list("thread_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.beta.threads.messages.list("thread_id")

              puts(page)
      description: Returns a list of messages for a given thread.
    post:
      operationId: createMessage
      tags:
        - Assistants
      summary: Create message
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: >-
            The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to create a message
            for.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Create message
        group: threads
        beta: true
        returns: A [message](https://platform.openai.com/docs/api-reference/messages/object) object.
        examples:
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1713226573,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              message = client.beta.threads.messages.create(
                  thread_id="thread_id",
                  content="string",
                  role="user",
              )
              print(message.id)
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              const message = await client.beta.threads.messages.create('thread_id', { content: 'string',
              role: 'user' });


              console.log(message.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                message, err := client.Beta.Threads.Messages.New(
                  context.TODO(),
                  "thread_id",
                  openai.BetaThreadMessageNewParams{
                    Content: openai.BetaThreadMessageNewParamsContentUnion{
                      OfString: openai.String("string"),
                    },
                    Role: openai.BetaThreadMessageNewParamsRoleUser,
                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", message.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.messages.Message;
              import com.openai.models.beta.threads.messages.MessageCreateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      MessageCreateParams params = MessageCreateParams.builder()
                          .threadId("thread_id")
                          .content("string")
                          .role(MessageCreateParams.Role.USER)
                          .build();
                      Message message = client.beta().threads().messages().create(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              message = openai.beta.threads.messages.create("thread_id", content: "string", role: :user)

              puts(message)
      description: Create a message.
  /threads/{thread_id}/messages/{message_id}:
    get:
      operationId: getMessage
      tags:
        - Assistants
      summary: Retrieve message
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: >-
            The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this
            message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to retrieve.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Retrieve message
        group: threads
        beta: true
        returns: >-
          The [message](https://platform.openai.com/docs/api-reference/messages/object) object matching the
          specified ID.
        examples:
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              message = client.beta.threads.messages.retrieve(
                  message_id="message_id",
                  thread_id="thread_id",
              )
              print(message.id)
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              const message = await client.beta.threads.messages.retrieve('message_id', { thread_id:
              'thread_id' });


              console.log(message.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                message, err := client.Beta.Threads.Messages.Get(
                  context.TODO(),
                  "thread_id",
                  "message_id",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", message.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.messages.Message;
              import com.openai.models.beta.threads.messages.MessageRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      MessageRetrieveParams params = MessageRetrieveParams.builder()
                          .threadId("thread_id")
                          .messageId("message_id")
                          .build();
                      Message message = client.beta().threads().messages().retrieve(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              message = openai.beta.threads.messages.retrieve("message_id", thread_id: "thread_id")

              puts(message)
      description: Retrieve a message.
    post:
      operationId: modifyMessage
      tags:
        - Assistants
      summary: Modify message
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Modify message
        group: threads
        beta: true
        returns: The modified [message](https://platform.openai.com/docs/api-reference/messages/object) object.
        examples:
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "file_ids": [],
              "metadata": {
                "modified": "true",
                "user": "abc123"
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              message = client.beta.threads.messages.update(
                  message_id="message_id",
                  thread_id="thread_id",
              )
              print(message.id)
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              const message = await client.beta.threads.messages.update('message_id', { thread_id: 'thread_id'
              });


              console.log(message.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                message, err := client.Beta.Threads.Messages.Update(
                  context.TODO(),
                  "thread_id",
                  "message_id",
                  openai.BetaThreadMessageUpdateParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", message.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.messages.Message;
              import com.openai.models.beta.threads.messages.MessageUpdateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      MessageUpdateParams params = MessageUpdateParams.builder()
                          .threadId("thread_id")
                          .messageId("message_id")
                          .build();
                      Message message = client.beta().threads().messages().update(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              message = openai.beta.threads.messages.update("message_id", thread_id: "thread_id")

              puts(message)
      description: Modifies a message.
    delete:
      operationId: deleteMessage
      tags:
        - Assistants
      summary: Delete message
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this message belongs.
        - in: path
          name: message_id
          required: true
          schema:
            type: string
          description: The ID of the message to delete.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
      x-oaiMeta:
        name: Delete message
        group: threads
        beta: true
        returns: Deletion status
        examples:
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message.deleted",
              "deleted": true
            }
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              message_deleted = client.beta.threads.messages.delete(
                  message_id="message_id",
                  thread_id="thread_id",
              )
              print(message_deleted.id)
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              const messageDeleted = await client.beta.threads.messages.delete('message_id', { thread_id:
              'thread_id' });


              console.log(messageDeleted.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                messageDeleted, err := client.Beta.Threads.Messages.Delete(
                  context.TODO(),
                  "thread_id",
                  "message_id",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", messageDeleted.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.messages.MessageDeleteParams;
              import com.openai.models.beta.threads.messages.MessageDeleted;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      MessageDeleteParams params = MessageDeleteParams.builder()
                          .threadId("thread_id")
                          .messageId("message_id")
                          .build();
                      MessageDeleted messageDeleted = client.beta().threads().messages().delete(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              message_deleted = openai.beta.threads.messages.delete("message_id", thread_id: "thread_id")

              puts(message_deleted)
      description: Deletes a message.
  /threads/{thread_id}/runs:
    get:
      operationId: listRuns
      tags:
        - Assistants
      summary: List runs
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the thread the run belongs to.
        - name: limit
          in: query
          description: >
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for
            descending order.
          schema:
            type: string
            default: desc
            enum:
              - asc
              - desc
        - name: after
          in: query
          description: >
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent
            call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: >
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, starting with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
      x-oaiMeta:
        name: List runs
        group: threads
        beta: true
        returns: A list of [run](https://platform.openai.com/docs/api-reference/runs/object) objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "run_abc123",
                  "object": "thread.run",
                  "created_at": 1699075072,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699075072,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699075073,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                },
                {
                  "id": "run_abc456",
                  "object": "thread.run",
                  "created_at": 1699063290,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699063290,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699063291,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                }
              ],
              "first_id": "run_abc123",
              "last_id": "run_abc456",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.beta.threads.runs.list(
                  thread_id="thread_id",
              )
              page = page.data[0]
              print(page.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const run of client.beta.threads.runs.list('thread_id')) {
                console.log(run.id);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.Beta.Threads.Runs.List(
                  context.TODO(),
                  "thread_id",
                  openai.BetaThreadRunListParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.runs.RunListPage;
              import com.openai.models.beta.threads.runs.RunListParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      RunListPage page = client.beta().threads().runs().list("thread_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.beta.threads.runs.list("thread_id")

              puts(page)
      description: Returns a list of runs belonging to a thread.
    post:
      operationId: createRun
      tags:
        - Assistants
      summary: Create run
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to run.
        - name: include[]
          in: query
          description: >
            A list of additional fields to include in the response. Currently the only supported value is
            `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result
            content.


            See the [file search tool
            documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)
            for more information.
          schema:
            type: array
            items:
              type: string
              enum:
                - step_details.tool_calls[*].file_search.results[*].content
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create run
        group: threads
        beta: true
        returns: A [run](https://platform.openai.com/docs/api-reference/runs/object) object.
        examples:
          - title: Default
            request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_abc123/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_abc123"
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.runs.create(
                    thread_id="thread_id",
                    assistant_id="assistant_id",
                )
                print(run.id)
              node.js: >-
                import OpenAI from 'openai';


                const client = new OpenAI({
                  apiKey: 'My API Key',
                });


                const run = await client.beta.threads.runs.create('thread_id', { assistant_id: 'assistant_id'
                });


                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.Runs.New(
                    context.TODO(),
                    "thread_id",
                    openai.BetaThreadRunNewParams{
                      AssistantID: "assistant_id",
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.runs.Run;
                import com.openai.models.beta.threads.runs.RunCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        RunCreateParams params = RunCreateParams.builder()
                            .threadId("thread_id")
                            .assistantId("assistant_id")
                            .build();
                        Run run = client.beta().threads().runs().create(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                run = openai.beta.threads.runs.create("thread_id", assistant_id: "assistant_id")

                puts(run)
            response: |
              {
                "id": "run_abc123",
                "object": "thread.run",
                "created_at": 1699063290,
                "assistant_id": "asst_abc123",
                "thread_id": "thread_abc123",
                "status": "queued",
                "started_at": 1699063290,
                "expires_at": null,
                "cancelled_at": null,
                "failed_at": null,
                "completed_at": 1699063291,
                "last_error": null,
                "model": "gpt-4o",
                "instructions": null,
                "incomplete_details": null,
                "tools": [
                  {
                    "type": "code_interpreter"
                  }
                ],
                "metadata": {},
                "usage": null,
                "temperature": 1.0,
                "top_p": 1.0,
                "max_prompt_tokens": 1000,
                "max_completion_tokens": 1000,
                "truncation_strategy": {
                  "type": "auto",
                  "last_messages": null
                },
                "response_format": "auto",
                "tool_choice": "auto",
                "parallel_tool_calls": true
              }
          - title: Streaming
            request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_123/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_123",
                    "stream": true
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.runs.create(
                    thread_id="thread_id",
                    assistant_id="assistant_id",
                )
                print(run.id)
              node.js: >-
                import OpenAI from 'openai';


                const client = new OpenAI({
                  apiKey: 'My API Key',
                });


                const run = await client.beta.threads.runs.create('thread_id', { assistant_id: 'assistant_id'
                });


                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.Runs.New(
                    context.TODO(),
                    "thread_id",
                    openai.BetaThreadRunNewParams{
                      AssistantID: "assistant_id",
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.runs.Run;
                import com.openai.models.beta.threads.runs.RunCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        RunCreateParams params = RunCreateParams.builder()
                            .threadId("thread_id")
                            .assistantId("assistant_id")
                            .build();
                        Run run = client.beta().threads().runs().create(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                run = openai.beta.threads.runs.create("thread_id", assistant_id: "assistant_id")

                puts(run)
            response: >
              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              today"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
              How can I assist you today?","annotations":[]}}],"metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


              event: thread.run.completed

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: done

              data: [DONE]
          - title: Streaming with Functions
            request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_abc123/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_abc123",
                    "tools": [
                      {
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "description": "Get the current weather in a given location",
                          "parameters": {
                            "type": "object",
                            "properties": {
                              "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                "type": "string",
                                "enum": ["celsius", "fahrenheit"]
                              }
                            },
                            "required": ["location"]
                          }
                        }
                      }
                    ],
                    "stream": true
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.runs.create(
                    thread_id="thread_id",
                    assistant_id="assistant_id",
                )
                print(run.id)
              node.js: >-
                import OpenAI from 'openai';


                const client = new OpenAI({
                  apiKey: 'My API Key',
                });


                const run = await client.beta.threads.runs.create('thread_id', { assistant_id: 'assistant_id'
                });


                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.Runs.New(
                    context.TODO(),
                    "thread_id",
                    openai.BetaThreadRunNewParams{
                      AssistantID: "assistant_id",
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.runs.Run;
                import com.openai.models.beta.threads.runs.RunCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        RunCreateParams params = RunCreateParams.builder()
                            .threadId("thread_id")
                            .assistantId("assistant_id")
                            .build();
                        Run run = client.beta().threads().runs().create(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                run = openai.beta.threads.runs.create("thread_id", assistant_id: "assistant_id")

                puts(run)
            response: >
              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              today"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
              How can I assist you today?","annotations":[]}}],"metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


              event: thread.run.completed

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: done

              data: [DONE]
      description: Create a run.
  /threads/{thread_id}/runs/{run_id}:
    get:
      operationId: getRun
      tags:
        - Assistants
      summary: Retrieve run
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to retrieve.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Retrieve run
        group: threads
        beta: true
        returns: >-
          The [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the specified
          ID.
        examples:
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              run = client.beta.threads.runs.retrieve(
                  run_id="run_id",
                  thread_id="thread_id",
              )
              print(run.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const run = await client.beta.threads.runs.retrieve('run_id', { thread_id: 'thread_id' });

              console.log(run.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                run, err := client.Beta.Threads.Runs.Get(
                  context.TODO(),
                  "thread_id",
                  "run_id",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", run.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.runs.Run;
              import com.openai.models.beta.threads.runs.RunRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      RunRetrieveParams params = RunRetrieveParams.builder()
                          .threadId("thread_id")
                          .runId("run_id")
                          .build();
                      Run run = client.beta().threads().runs().retrieve(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              run = openai.beta.threads.runs.retrieve("run_id", thread_id: "thread_id")

              puts(run)
      description: Retrieves a run.
    post:
      operationId: modifyRun
      tags:
        - Assistants
      summary: Modify run
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Modify run
        group: threads
        beta: true
        returns: >-
          The modified [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the
          specified ID.
        examples:
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": [
                    "file-abc123",
                    "file-abc456"
                  ]
                }
              },
              "metadata": {
                "user_id": "user_abc123"
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "metadata": {
                    "user_id": "user_abc123"
                  }
                }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              run = client.beta.threads.runs.update(
                  run_id="run_id",
                  thread_id="thread_id",
              )
              print(run.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const run = await client.beta.threads.runs.update('run_id', { thread_id: 'thread_id' });

              console.log(run.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                run, err := client.Beta.Threads.Runs.Update(
                  context.TODO(),
                  "thread_id",
                  "run_id",
                  openai.BetaThreadRunUpdateParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", run.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.runs.Run;
              import com.openai.models.beta.threads.runs.RunUpdateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      RunUpdateParams params = RunUpdateParams.builder()
                          .threadId("thread_id")
                          .runId("run_id")
                          .build();
                      Run run = client.beta().threads().runs().update(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              run = openai.beta.threads.runs.update("run_id", thread_id: "thread_id")

              puts(run)
      description: Modifies a run.
  /threads/{thread_id}/runs/{run_id}/cancel:
    post:
      operationId: cancelRun
      tags:
        - Assistants
      summary: Cancel a run
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which this run belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to cancel.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Cancel a run
        group: threads
        beta: true
        returns: >-
          The modified [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the
          specified ID.
        examples:
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076126,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "cancelling",
              "started_at": 1699076126,
              "expires_at": 1699076726,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You summarize books.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              run = client.beta.threads.runs.cancel(
                  run_id="run_id",
                  thread_id="thread_id",
              )
              print(run.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const run = await client.beta.threads.runs.cancel('run_id', { thread_id: 'thread_id' });

              console.log(run.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                run, err := client.Beta.Threads.Runs.Cancel(
                  context.TODO(),
                  "thread_id",
                  "run_id",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", run.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.runs.Run;
              import com.openai.models.beta.threads.runs.RunCancelParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      RunCancelParams params = RunCancelParams.builder()
                          .threadId("thread_id")
                          .runId("run_id")
                          .build();
                      Run run = client.beta().threads().runs().cancel(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              run = openai.beta.threads.runs.cancel("run_id", thread_id: "thread_id")

              puts(run)
      description: Cancels a run that is `in_progress`.
  /threads/{thread_id}/runs/{run_id}/steps:
    get:
      operationId: listRunSteps
      tags:
        - Assistants
      summary: List run steps
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the thread the run and run steps belong to.
        - name: run_id
          in: path
          required: true
          schema:
            type: string
          description: The ID of the run the run steps belong to.
        - name: limit
          in: query
          description: >
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for
            descending order.
          schema:
            type: string
            default: desc
            enum:
              - asc
              - desc
        - name: after
          in: query
          description: >
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent
            call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: >
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, starting with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
        - name: include[]
          in: query
          description: >
            A list of additional fields to include in the response. Currently the only supported value is
            `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result
            content.


            See the [file search tool
            documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)
            for more information.
          schema:
            type: array
            items:
              type: string
              enum:
                - step_details.tool_calls[*].file_search.results[*].content
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
      x-oaiMeta:
        name: List run steps
        group: threads
        beta: true
        returns: A list of [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "step_abc123",
                  "object": "thread.run.step",
                  "created_at": 1699063291,
                  "run_id": "run_abc123",
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "type": "message_creation",
                  "status": "completed",
                  "cancelled_at": null,
                  "completed_at": 1699063291,
                  "expired_at": null,
                  "failed_at": null,
                  "last_error": null,
                  "step_details": {
                    "type": "message_creation",
                    "message_creation": {
                      "message_id": "msg_abc123"
                    }
                  },
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  }
                }
              ],
              "first_id": "step_abc123",
              "last_id": "step_abc456",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.beta.threads.runs.steps.list(
                  run_id="run_id",
                  thread_id="thread_id",
              )
              page = page.data[0]
              print(page.id)
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              // Automatically fetches more pages as needed.

              for await (const runStep of client.beta.threads.runs.steps.list('run_id', { thread_id:
              'thread_id' })) {
                console.log(runStep.id);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.Beta.Threads.Runs.Steps.List(
                  context.TODO(),
                  "thread_id",
                  "run_id",
                  openai.BetaThreadRunStepListParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.runs.steps.StepListPage;
              import com.openai.models.beta.threads.runs.steps.StepListParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      StepListParams params = StepListParams.builder()
                          .threadId("thread_id")
                          .runId("run_id")
                          .build();
                      StepListPage page = client.beta().threads().runs().steps().list(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.beta.threads.runs.steps.list("run_id", thread_id: "thread_id")

              puts(page)
      description: Returns a list of run steps belonging to a run.
  /threads/{thread_id}/runs/{run_id}/steps/{step_id}:
    get:
      operationId: getRunStep
      tags:
        - Assistants
      summary: Retrieve run step
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: The ID of the thread to which the run and run step belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run to which the run step belongs.
        - in: path
          name: step_id
          required: true
          schema:
            type: string
          description: The ID of the run step to retrieve.
        - name: include[]
          in: query
          description: >
            A list of additional fields to include in the response. Currently the only supported value is
            `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result
            content.


            See the [file search tool
            documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings)
            for more information.
          schema:
            type: array
            items:
              type: string
              enum:
                - step_details.tool_calls[*].file_search.results[*].content
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
      x-oaiMeta:
        name: Retrieve run step
        group: threads
        beta: true
        returns: >-
          The [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object) object matching
          the specified ID.
        examples:
          response: |
            {
              "id": "step_abc123",
              "object": "thread.run.step",
              "created_at": 1699063291,
              "run_id": "run_abc123",
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "type": "message_creation",
              "status": "completed",
              "cancelled_at": null,
              "completed_at": 1699063291,
              "expired_at": null,
              "failed_at": null,
              "last_error": null,
              "step_details": {
                "type": "message_creation",
                "message_creation": {
                  "message_id": "msg_abc123"
                }
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              run_step = client.beta.threads.runs.steps.retrieve(
                  step_id="step_id",
                  thread_id="thread_id",
                  run_id="run_id",
              )
              print(run_step.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const runStep = await client.beta.threads.runs.steps.retrieve('step_id', {
                thread_id: 'thread_id',
                run_id: 'run_id',
              });

              console.log(runStep.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                runStep, err := client.Beta.Threads.Runs.Steps.Get(
                  context.TODO(),
                  "thread_id",
                  "run_id",
                  "step_id",
                  openai.BetaThreadRunStepGetParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", runStep.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.beta.threads.runs.steps.RunStep;
              import com.openai.models.beta.threads.runs.steps.StepRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      StepRetrieveParams params = StepRetrieveParams.builder()
                          .threadId("thread_id")
                          .runId("run_id")
                          .stepId("step_id")
                          .build();
                      RunStep runStep = client.beta().threads().runs().steps().retrieve(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              run_step = openai.beta.threads.runs.steps.retrieve("step_id", thread_id: "thread_id", run_id:
              "run_id")


              puts(run_step)
      description: Retrieves a run step.
  /threads/{thread_id}/runs/{run_id}/submit_tool_outputs:
    post:
      operationId: submitToolOuputsToRun
      tags:
        - Assistants
      summary: Submit tool outputs to run
      parameters:
        - in: path
          name: thread_id
          required: true
          schema:
            type: string
          description: >-
            The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this run
            belongs.
        - in: path
          name: run_id
          required: true
          schema:
            type: string
          description: The ID of the run that requires the tool output submission.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Submit tool outputs to run
        group: threads
        beta: true
        returns: >-
          The modified [run](https://platform.openai.com/docs/api-reference/runs/object) object matching the
          specified ID.
        examples:
          - title: Default
            request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "tool_outputs": [
                      {
                        "tool_call_id": "call_001",
                        "output": "70 degrees and sunny."
                      }
                    ]
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.runs.submit_tool_outputs(
                    run_id="run_id",
                    thread_id="thread_id",
                    tool_outputs=[{}],
                )
                print(run.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const run = await client.beta.threads.runs.submitToolOutputs('run_id', {
                  thread_id: 'thread_id',
                  tool_outputs: [{}],
                });

                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.Runs.SubmitToolOutputs(
                    context.TODO(),
                    "thread_id",
                    "run_id",
                    openai.BetaThreadRunSubmitToolOutputsParams{
                      ToolOutputs: []openai.BetaThreadRunSubmitToolOutputsParamsToolOutput{openai.BetaThreadRunSubmitToolOutputsParamsToolOutput{

                      }},
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.runs.Run;
                import com.openai.models.beta.threads.runs.RunSubmitToolOutputsParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        RunSubmitToolOutputsParams params = RunSubmitToolOutputsParams.builder()
                            .threadId("thread_id")
                            .runId("run_id")
                            .addToolOutput(RunSubmitToolOutputsParams.ToolOutput.builder().build())
                            .build();
                        Run run = client.beta().threads().runs().submitToolOutputs(params);
                    }
                }
              ruby: >-
                require "openai"


                openai = OpenAI::Client.new(api_key: "My API Key")


                run = openai.beta.threads.runs.submit_tool_outputs("run_id", thread_id: "thread_id",
                tool_outputs: [{}])


                puts(run)
            response: |
              {
                "id": "run_123",
                "object": "thread.run",
                "created_at": 1699075592,
                "assistant_id": "asst_123",
                "thread_id": "thread_123",
                "status": "queued",
                "started_at": 1699075592,
                "expires_at": 1699076192,
                "cancelled_at": null,
                "failed_at": null,
                "completed_at": null,
                "last_error": null,
                "model": "gpt-4o",
                "instructions": null,
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "metadata": {},
                "usage": null,
                "temperature": 1.0,
                "top_p": 1.0,
                "max_prompt_tokens": 1000,
                "max_completion_tokens": 1000,
                "truncation_strategy": {
                  "type": "auto",
                  "last_messages": null
                },
                "response_format": "auto",
                "tool_choice": "auto",
                "parallel_tool_calls": true
              }
          - title: Streaming
            request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "tool_outputs": [
                      {
                        "tool_call_id": "call_001",
                        "output": "70 degrees and sunny."
                      }
                    ],
                    "stream": true
                  }'
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                run = client.beta.threads.runs.submit_tool_outputs(
                    run_id="run_id",
                    thread_id="thread_id",
                    tool_outputs=[{}],
                )
                print(run.id)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const run = await client.beta.threads.runs.submitToolOutputs('run_id', {
                  thread_id: 'thread_id',
                  tool_outputs: [{}],
                });

                console.log(run.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  run, err := client.Beta.Threads.Runs.SubmitToolOutputs(
                    context.TODO(),
                    "thread_id",
                    "run_id",
                    openai.BetaThreadRunSubmitToolOutputsParams{
                      ToolOutputs: []openai.BetaThreadRunSubmitToolOutputsParamsToolOutput{openai.BetaThreadRunSubmitToolOutputsParamsToolOutput{

                      }},
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", run.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.beta.threads.runs.Run;
                import com.openai.models.beta.threads.runs.RunSubmitToolOutputsParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        RunSubmitToolOutputsParams params = RunSubmitToolOutputsParams.builder()
                            .threadId("thread_id")
                            .runId("run_id")
                            .addToolOutput(RunSubmitToolOutputsParams.ToolOutput.builder().build())
                            .build();
                        Run run = client.beta().threads().runs().submitToolOutputs(params);
                    }
                }
              ruby: >-
                require "openai"


                openai = OpenAI::Client.new(api_key: "My API Key")


                run = openai.beta.threads.runs.submit_tool_outputs("run_id", thread_id: "thread_id",
                tool_outputs: [{}])


                puts(run)
            response: >
              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San
              Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and
              sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: thread.run.step.created

              data:
              {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              current"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              weather"}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              sunny"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The
              current weather in San Francisco, CA is 70 degrees Fahrenheit and
              sunny.","annotations":[]}}],"metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}


              event: thread.run.completed

              data:
              {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


              event: done

              data: [DONE]
      description: >
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`,
        this endpoint can be used to submit the outputs from the tool calls once they're all completed. All
        outputs must be submitted in a single request.
  /uploads:
    post:
      operationId: createUpload
      tags:
        - Uploads
      summary: Create upload
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUploadRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Create upload
        group: uploads
        returns: >-
          The [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object with status
          `pending`.
        examples:
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "pending",
              "expires_at": 1719127296
            }
          request:
            curl: |
              curl https://api.openai.com/v1/uploads \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "purpose": "fine-tune",
                  "filename": "training_examples.jsonl",
                  "bytes": 2147483648,
                  "mime_type": "text/jsonl",
                  "expires_after": {
                    "anchor": "created_at",
                    "seconds": 3600
                  }
                }'
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const upload = await client.uploads.create({
                bytes: 0,
                filename: 'filename',
                mime_type: 'mime_type',
                purpose: 'assistants',
              });

              console.log(upload.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              upload = client.uploads.create(
                  bytes=0,
                  filename="filename",
                  mime_type="mime_type",
                  purpose="assistants",
              )
              print(upload.id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                upload, err := client.Uploads.New(context.TODO(), openai.UploadNewParams{
                  Bytes: 0,
                  Filename: "filename",
                  MimeType: "mime_type",
                  Purpose: openai.FilePurposeAssistants,
                })
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", upload.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.files.FilePurpose;
              import com.openai.models.uploads.Upload;
              import com.openai.models.uploads.UploadCreateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      UploadCreateParams params = UploadCreateParams.builder()
                          .bytes(0L)
                          .filename("filename")
                          .mimeType("mime_type")
                          .purpose(FilePurpose.ASSISTANTS)
                          .build();
                      Upload upload = client.uploads().create(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              upload = openai.uploads.create(bytes: 0, filename: "filename", mime_type: "mime_type", purpose:
              :assistants)


              puts(upload)
      description: >
        Creates an intermediate [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object

        that you can add [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.

        Currently, an Upload can accept at most 8 GB in total and expires after an

        hour after you create it.


        Once you complete the Upload, we will create a

        [File](https://platform.openai.com/docs/api-reference/files/object) object that contains all the parts

        you uploaded. This File is usable in the rest of our platform as a regular

        File object.


        For certain `purpose` values, the correct `mime_type` must be specified. 

        Please refer to documentation for the 

        [supported MIME types for your use
        case](https://platform.openai.com/docs/assistants/tools/file-search#supported-files).


        For guidance on the proper filename extensions for each purpose, please

        follow the documentation on [creating a

        File](https://platform.openai.com/docs/api-reference/files/create).
  /uploads/{upload_id}/cancel:
    post:
      operationId: cancelUpload
      tags:
        - Uploads
      summary: Cancel upload
      parameters:
        - in: path
          name: upload_id
          required: true
          schema:
            type: string
            example: upload_abc123
          description: |
            The ID of the Upload.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Cancel upload
        group: uploads
        returns: >-
          The [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object with status
          `cancelled`.
        examples:
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "cancelled",
              "expires_at": 1719127296
            }
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/cancel
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const upload = await client.uploads.cancel('upload_abc123');

              console.log(upload.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              upload = client.uploads.cancel(
                  "upload_abc123",
              )
              print(upload.id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                upload, err := client.Uploads.Cancel(context.TODO(), "upload_abc123")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", upload.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.uploads.Upload;
              import com.openai.models.uploads.UploadCancelParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      Upload upload = client.uploads().cancel("upload_abc123");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              upload = openai.uploads.cancel("upload_abc123")

              puts(upload)
      description: |
        Cancels the Upload. No Parts may be added after an Upload is cancelled.
  /uploads/{upload_id}/complete:
    post:
      operationId: completeUpload
      tags:
        - Uploads
      summary: Complete upload
      parameters:
        - in: path
          name: upload_id
          required: true
          schema:
            type: string
            example: upload_abc123
          description: |
            The ID of the Upload.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompleteUploadRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Complete upload
        group: uploads
        returns: >-
          The [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object with status
          `completed` with an additional `file` property containing the created usable File object.
        examples:
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "completed",
              "expires_at": 1719127296,
              "file": {
                "id": "file-xyz321",
                "object": "file",
                "bytes": 2147483648,
                "created_at": 1719186911,
                "expires_at": 1719127296,
                "filename": "training_examples.jsonl",
                "purpose": "fine-tune",
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/complete
                -d '{
                  "part_ids": ["part_def456", "part_ghi789"]
                }'
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const upload = await client.uploads.complete('upload_abc123', { part_ids: ['string'] });

              console.log(upload.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              upload = client.uploads.complete(
                  upload_id="upload_abc123",
                  part_ids=["string"],
              )
              print(upload.id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                upload, err := client.Uploads.Complete(
                  context.TODO(),
                  "upload_abc123",
                  openai.UploadCompleteParams{
                    PartIDs: []string{"string"},
                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", upload.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.uploads.Upload;
              import com.openai.models.uploads.UploadCompleteParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      UploadCompleteParams params = UploadCompleteParams.builder()
                          .uploadId("upload_abc123")
                          .addPartId("string")
                          .build();
                      Upload upload = client.uploads().complete(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              upload = openai.uploads.complete("upload_abc123", part_ids: ["string"])

              puts(upload)
      description: >
        Completes the [Upload](https://platform.openai.com/docs/api-reference/uploads/object). 


        Within the returned Upload object, there is a nested
        [File](https://platform.openai.com/docs/api-reference/files/object) object that is ready to use in the
        rest of the platform.


        You can specify the order of the Parts by passing in an ordered list of the Part IDs.


        The number of bytes uploaded upon completion must match the number of bytes initially specified when
        creating the Upload object. No Parts may be added after an Upload is completed.
  /uploads/{upload_id}/parts:
    post:
      operationId: addUploadPart
      tags:
        - Uploads
      summary: Add upload part
      parameters:
        - in: path
          name: upload_id
          required: true
          schema:
            type: string
            example: upload_abc123
          description: |
            The ID of the Upload.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AddUploadPartRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UploadPart'
      x-oaiMeta:
        name: Add upload part
        group: uploads
        returns: The upload [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) object.
        examples:
          response: |
            {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719185911,
              "upload_id": "upload_abc123"
            }
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/parts
                -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const uploadPart = await client.uploads.parts.create('upload_abc123', {
                data: fs.createReadStream('path/to/file'),
              });

              console.log(uploadPart.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              upload_part = client.uploads.parts.create(
                  upload_id="upload_abc123",
                  data=b"raw file contents",
              )
              print(upload_part.id)
            go: |
              package main

              import (
                "bytes"
                "context"
                "fmt"
                "io"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                uploadPart, err := client.Uploads.Parts.New(
                  context.TODO(),
                  "upload_abc123",
                  openai.UploadPartNewParams{
                    Data: io.Reader(bytes.NewBuffer([]byte("some file contents"))),
                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", uploadPart.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.uploads.parts.PartCreateParams;
              import com.openai.models.uploads.parts.UploadPart;
              import java.io.ByteArrayInputStream;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      PartCreateParams params = PartCreateParams.builder()
                          .uploadId("upload_abc123")
                          .data(ByteArrayInputStream("some content".getBytes()))
                          .build();
                      UploadPart uploadPart = client.uploads().parts().create(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              upload_part = openai.uploads.parts.create("upload_abc123", data: Pathname(__FILE__))

              puts(upload_part)
      description: >
        Adds a [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an
        [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object. A Part represents a
        chunk of bytes from the file you are trying to upload. 


        Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.


        It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when
        you [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).
  /vector_stores:
    get:
      operationId: listVectorStores
      tags:
        - Vector stores
      summary: List vector stores
      parameters:
        - name: limit
          in: query
          description: >
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for
            descending order.
          schema:
            type: string
            default: desc
            enum:
              - asc
              - desc
        - name: after
          in: query
          description: >
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent
            call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: >
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, starting with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
      x-oaiMeta:
        name: List vector stores
        group: vector_stores
        returns: >-
          A list of [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)
          objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "vs_abc123",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ",
                  "description": "Contains commonly asked questions and answers, organized by topic.",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                },
                {
                  "id": "vs_abc456",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ v2",
                  "description": null,
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                }
              ],
              "first_id": "vs_abc123",
              "last_id": "vs_abc456",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.vector_stores.list()
              page = page.data[0]
              print(page.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const vectorStore of client.vectorStores.list()) {
                console.log(vectorStore.id);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.VectorStores.List(context.TODO(), openai.VectorStoreListParams{

                })
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.VectorStoreListPage;
              import com.openai.models.vectorstores.VectorStoreListParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStoreListPage page = client.vectorStores().list();
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.vector_stores.list

              puts(page)
      description: Returns a list of vector stores.
    post:
      operationId: createVectorStore
      tags:
        - Vector stores
      summary: Create vector store
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Create vector store
        group: vector_stores
        returns: A [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) object.
        examples:
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "description": "Contains commonly asked questions and answers, organized by topic.",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "name": "Support FAQ"
                }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store = client.vector_stores.create()
              print(vector_store.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStore = await client.vectorStores.create();

              console.log(vectorStore.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStore, err := client.VectorStores.New(context.TODO(), openai.VectorStoreNewParams{

                })
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStore.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.VectorStore;
              import com.openai.models.vectorstores.VectorStoreCreateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStore vectorStore = client.vectorStores().create();
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store = openai.vector_stores.create

              puts(vector_store)
      description: Create a vector store.
  /vector_stores/{vector_store_id}:
    get:
      operationId: getVectorStore
      tags:
        - Vector stores
      summary: Retrieve vector store
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store to retrieve.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Retrieve vector store
        group: vector_stores
        returns: >-
          The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) object
          matching the specified ID.
        examples:
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store = client.vector_stores.retrieve(
                  "vector_store_id",
              )
              print(vector_store.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStore = await client.vectorStores.retrieve('vector_store_id');

              console.log(vectorStore.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStore, err := client.VectorStores.Get(context.TODO(), "vector_store_id")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStore.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.VectorStore;
              import com.openai.models.vectorstores.VectorStoreRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStore vectorStore = client.vectorStores().retrieve("vector_store_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store = openai.vector_stores.retrieve("vector_store_id")

              puts(vector_store)
      description: Retrieves a vector store.
    post:
      operationId: modifyVectorStore
      tags:
        - Vector stores
      summary: Modify vector store
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store to modify.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Modify vector store
        group: vector_stores
        returns: >-
          The modified [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)
          object.
        examples:
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "description": "Contains commonly asked questions and answers, organized by topic.",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store = client.vector_stores.update(
                  vector_store_id="vector_store_id",
              )
              print(vector_store.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStore = await client.vectorStores.update('vector_store_id');

              console.log(vectorStore.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStore, err := client.VectorStores.Update(
                  context.TODO(),
                  "vector_store_id",
                  openai.VectorStoreUpdateParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStore.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.VectorStore;
              import com.openai.models.vectorstores.VectorStoreUpdateParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStore vectorStore = client.vectorStores().update("vector_store_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store = openai.vector_stores.update("vector_store_id")

              puts(vector_store)
      description: Modifies a vector store.
    delete:
      operationId: deleteVectorStore
      tags:
        - Vector stores
      summary: Delete vector store
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store to delete.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
      x-oaiMeta:
        name: Delete vector store
        group: vector_stores
        returns: Deletion status
        examples:
          response: |
            {
              id: "vs_abc123",
              object: "vector_store.deleted",
              deleted: true
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_deleted = client.vector_stores.delete(
                  "vector_store_id",
              )
              print(vector_store_deleted.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreDeleted = await client.vectorStores.delete('vector_store_id');

              console.log(vectorStoreDeleted.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreDeleted, err := client.VectorStores.Delete(context.TODO(), "vector_store_id")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreDeleted.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.VectorStoreDeleteParams;
              import com.openai.models.vectorstores.VectorStoreDeleted;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStoreDeleted vectorStoreDeleted = client.vectorStores().delete("vector_store_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store_deleted = openai.vector_stores.delete("vector_store_id")

              puts(vector_store_deleted)
      description: Delete a vector store.
  /vector_stores/{vector_store_id}/file_batches:
    post:
      operationId: createVectorStoreFileBatch
      tags:
        - Vector stores
      summary: Create vector store file batch
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: |
            The ID of the vector store for which to create a File Batch.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Create vector store file batch
        group: vector_stores
        returns: >-
          A [vector store file
          batch](https://platform.openai.com/docs/api-reference/vector-stores-file-batches/batch-object)
          object.
        examples:
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "files": [
                      {
                        "file_id": "file-abc123",
                        "attributes": {"category": "finance"}
                      },
                      {
                        "file_id": "file-abc456",
                        "chunking_strategy": {
                          "type": "static",
                          "max_chunk_size_tokens": 1200,
                          "chunk_overlap_tokens": 200
                        }
                      }
                    ]
                  }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file_batch = client.vector_stores.file_batches.create(
                  vector_store_id="vs_abc123",
              )
              print(vector_store_file_batch.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreFileBatch = await client.vectorStores.fileBatches.create('vs_abc123');

              console.log(vectorStoreFileBatch.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFileBatch, err := client.VectorStores.FileBatches.New(
                  context.TODO(),
                  "vs_abc123",
                  openai.VectorStoreFileBatchNewParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFileBatch.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.filebatches.FileBatchCreateParams;
              import com.openai.models.vectorstores.filebatches.VectorStoreFileBatch;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStoreFileBatch vectorStoreFileBatch = client.vectorStores().fileBatches().create("vs_abc123");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store_file_batch = openai.vector_stores.file_batches.create("vs_abc123")

              puts(vector_store_file_batch)
      description: Create a vector store file batch.
  /vector_stores/{vector_store_id}/file_batches/{batch_id}:
    get:
      operationId: getVectorStoreFileBatch
      tags:
        - Vector stores
      summary: Retrieve vector store file batch
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store that the file batch belongs to.
        - in: path
          name: batch_id
          required: true
          schema:
            type: string
            example: vsfb_abc123
          description: The ID of the file batch being retrieved.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Retrieve vector store file batch
        group: vector_stores
        returns: >-
          The [vector store file
          batch](https://platform.openai.com/docs/api-reference/vector-stores-file-batches/batch-object)
          object.
        examples:
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file_batch = client.vector_stores.file_batches.retrieve(
                  batch_id="vsfb_abc123",
                  vector_store_id="vs_abc123",
              )
              print(vector_store_file_batch.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreFileBatch = await client.vectorStores.fileBatches.retrieve('vsfb_abc123', {
                vector_store_id: 'vs_abc123',
              });

              console.log(vectorStoreFileBatch.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFileBatch, err := client.VectorStores.FileBatches.Get(
                  context.TODO(),
                  "vs_abc123",
                  "vsfb_abc123",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFileBatch.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.filebatches.FileBatchRetrieveParams;
              import com.openai.models.vectorstores.filebatches.VectorStoreFileBatch;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileBatchRetrieveParams params = FileBatchRetrieveParams.builder()
                          .vectorStoreId("vs_abc123")
                          .batchId("vsfb_abc123")
                          .build();
                      VectorStoreFileBatch vectorStoreFileBatch = client.vectorStores().fileBatches().retrieve(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              vector_store_file_batch = openai.vector_stores.file_batches.retrieve("vsfb_abc123",
              vector_store_id: "vs_abc123")


              puts(vector_store_file_batch)
      description: Retrieves a vector store file batch.
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel:
    post:
      operationId: cancelVectorStoreFileBatch
      tags:
        - Vector stores
      summary: Cancel vector store file batch
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store that the file batch belongs to.
        - in: path
          name: batch_id
          required: true
          schema:
            type: string
          description: The ID of the file batch to cancel.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Cancel vector store file batch
        group: vector_stores
        returns: The modified vector store file batch object.
        examples:
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 12,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 15,
              }
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file_batch = client.vector_stores.file_batches.cancel(
                  batch_id="batch_id",
                  vector_store_id="vector_store_id",
              )
              print(vector_store_file_batch.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreFileBatch = await client.vectorStores.fileBatches.cancel('batch_id', {
                vector_store_id: 'vector_store_id',
              });

              console.log(vectorStoreFileBatch.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFileBatch, err := client.VectorStores.FileBatches.Cancel(
                  context.TODO(),
                  "vector_store_id",
                  "batch_id",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFileBatch.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.filebatches.FileBatchCancelParams;
              import com.openai.models.vectorstores.filebatches.VectorStoreFileBatch;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileBatchCancelParams params = FileBatchCancelParams.builder()
                          .vectorStoreId("vector_store_id")
                          .batchId("batch_id")
                          .build();
                      VectorStoreFileBatch vectorStoreFileBatch = client.vectorStores().fileBatches().cancel(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              vector_store_file_batch = openai.vector_stores.file_batches.cancel("batch_id", vector_store_id:
              "vector_store_id")


              puts(vector_store_file_batch)
      description: >-
        Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as
        soon as possible.
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/files:
    get:
      operationId: listFilesInVectorStoreBatch
      tags:
        - Vector stores
      summary: List vector store files in a batch
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: batch_id
          in: path
          description: The ID of the file batch that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: >
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for
            descending order.
          schema:
            type: string
            default: desc
            enum:
              - asc
              - desc
        - name: after
          in: query
          description: >
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent
            call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: >
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, starting with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
        - name: filter
          in: query
          description: Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.
          schema:
            type: string
            enum:
              - in_progress
              - completed
              - failed
              - cancelled
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files in a batch
        group: vector_stores
        returns: >-
          A list of [vector store
          file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.vector_stores.file_batches.list_files(
                  batch_id="batch_id",
                  vector_store_id="vector_store_id",
              )
              page = page.data[0]
              print(page.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const vectorStoreFile of client.vectorStores.fileBatches.listFiles('batch_id', {
                vector_store_id: 'vector_store_id',
              })) {
                console.log(vectorStoreFile.id);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.VectorStores.FileBatches.ListFiles(
                  context.TODO(),
                  "vector_store_id",
                  "batch_id",
                  openai.VectorStoreFileBatchListFilesParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.filebatches.FileBatchListFilesPage;
              import com.openai.models.vectorstores.filebatches.FileBatchListFilesParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileBatchListFilesParams params = FileBatchListFilesParams.builder()
                          .vectorStoreId("vector_store_id")
                          .batchId("batch_id")
                          .build();
                      FileBatchListFilesPage page = client.vectorStores().fileBatches().listFiles(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              page = openai.vector_stores.file_batches.list_files("batch_id", vector_store_id:
              "vector_store_id")


              puts(page)
      description: Returns a list of vector store files in a batch.
  /vector_stores/{vector_store_id}/files:
    get:
      operationId: listVectorStoreFiles
      tags:
        - Vector stores
      summary: List vector store files
      parameters:
        - name: vector_store_id
          in: path
          description: The ID of the vector store that the files belong to.
          required: true
          schema:
            type: string
        - name: limit
          in: query
          description: >
            A limit on the number of objects to be returned. Limit can range between 1 and 100, and the
            default is 20.
          required: false
          schema:
            type: integer
            default: 20
        - name: order
          in: query
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for
            descending order.
          schema:
            type: string
            default: desc
            enum:
              - asc
              - desc
        - name: after
          in: query
          description: >
            A cursor for use in pagination. `after` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent
            call can include after=obj_foo in order to fetch the next page of the list.
          schema:
            type: string
        - name: before
          in: query
          description: >
            A cursor for use in pagination. `before` is an object ID that defines your place in the list. For
            instance, if you make a list request and receive 100 objects, starting with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the previous page of the list.
          schema:
            type: string
        - name: filter
          in: query
          description: Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.
          schema:
            type: string
            enum:
              - in_progress
              - completed
              - failed
              - cancelled
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files
        group: vector_stores
        returns: >-
          A list of [vector store
          file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) objects.
        examples:
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.vector_stores.files.list(
                  vector_store_id="vector_store_id",
              )
              page = page.data[0]
              print(page.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const vectorStoreFile of client.vectorStores.files.list('vector_store_id')) {
                console.log(vectorStoreFile.id);
              }
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.VectorStores.Files.List(
                  context.TODO(),
                  "vector_store_id",
                  openai.VectorStoreFileListParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.files.FileListPage;
              import com.openai.models.vectorstores.files.FileListParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileListPage page = client.vectorStores().files().list("vector_store_id");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.vector_stores.files.list("vector_store_id")

              puts(page)
      description: Returns a list of vector store files.
    post:
      operationId: createVectorStoreFile
      tags:
        - Vector stores
      summary: Create vector store file
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: |
            The ID of the vector store for which to create a File.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Create vector store file
        group: vector_stores
        returns: >-
          A [vector store
          file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) object.
        examples:
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "usage_bytes": 1234,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_id": "file-abc123"
                  }'
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file = client.vector_stores.files.create(
                  vector_store_id="vs_abc123",
                  file_id="file_id",
              )
              print(vector_store_file.id)
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              const vectorStoreFile = await client.vectorStores.files.create('vs_abc123', { file_id: 'file_id'
              });


              console.log(vectorStoreFile.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFile, err := client.VectorStores.Files.New(
                  context.TODO(),
                  "vs_abc123",
                  openai.VectorStoreFileNewParams{
                    FileID: "file_id",
                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFile.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.files.FileCreateParams;
              import com.openai.models.vectorstores.files.VectorStoreFile;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileCreateParams params = FileCreateParams.builder()
                          .vectorStoreId("vs_abc123")
                          .fileId("file_id")
                          .build();
                      VectorStoreFile vectorStoreFile = client.vectorStores().files().create(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store_file = openai.vector_stores.files.create("vs_abc123", file_id: "file_id")

              puts(vector_store_file)
      description: >-
        Create a vector store file by attaching a [File](https://platform.openai.com/docs/api-reference/files)
        to a [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).
  /vector_stores/{vector_store_id}/files/{file_id}:
    get:
      operationId: getVectorStoreFile
      tags:
        - Vector stores
      summary: Retrieve vector store file
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store that the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
            example: file-abc123
          description: The ID of the file being retrieved.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Retrieve vector store file
        group: vector_stores
        returns: >-
          The [vector store
          file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) object.
        examples:
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file = client.vector_stores.files.retrieve(
                  file_id="file-abc123",
                  vector_store_id="vs_abc123",
              )
              print(vector_store_file.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreFile = await client.vectorStores.files.retrieve('file-abc123', {
                vector_store_id: 'vs_abc123',
              });

              console.log(vectorStoreFile.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFile, err := client.VectorStores.Files.Get(
                  context.TODO(),
                  "vs_abc123",
                  "file-abc123",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFile.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.files.FileRetrieveParams;
              import com.openai.models.vectorstores.files.VectorStoreFile;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileRetrieveParams params = FileRetrieveParams.builder()
                          .vectorStoreId("vs_abc123")
                          .fileId("file-abc123")
                          .build();
                      VectorStoreFile vectorStoreFile = client.vectorStores().files().retrieve(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              vector_store_file = openai.vector_stores.files.retrieve("file-abc123", vector_store_id:
              "vs_abc123")


              puts(vector_store_file)
      description: Retrieves a vector store file.
    delete:
      operationId: deleteVectorStoreFile
      tags:
        - Vector stores
      summary: Delete vector store file
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
          description: The ID of the vector store that the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
          description: The ID of the file to delete.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
      x-oaiMeta:
        name: Delete vector store file
        group: vector_stores
        returns: Deletion status
        examples:
          response: |
            {
              id: "file-abc123",
              object: "vector_store.file.deleted",
              deleted: true
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file_deleted = client.vector_stores.files.delete(
                  file_id="file_id",
                  vector_store_id="vector_store_id",
              )
              print(vector_store_file_deleted.id)
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreFileDeleted = await client.vectorStores.files.delete('file_id', {
                vector_store_id: 'vector_store_id',
              });

              console.log(vectorStoreFileDeleted.id);
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFileDeleted, err := client.VectorStores.Files.Delete(
                  context.TODO(),
                  "vector_store_id",
                  "file_id",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFileDeleted.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.files.FileDeleteParams;
              import com.openai.models.vectorstores.files.VectorStoreFileDeleted;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileDeleteParams params = FileDeleteParams.builder()
                          .vectorStoreId("vector_store_id")
                          .fileId("file_id")
                          .build();
                      VectorStoreFileDeleted vectorStoreFileDeleted = client.vectorStores().files().delete(params);
                  }
              }
            ruby: >-
              require "openai"


              openai = OpenAI::Client.new(api_key: "My API Key")


              vector_store_file_deleted = openai.vector_stores.files.delete("file_id", vector_store_id:
              "vector_store_id")


              puts(vector_store_file_deleted)
      description: >-
        Delete a vector store file. This will remove the file from the vector store but the file itself will
        not be deleted. To delete the file, use the [delete
        file](https://platform.openai.com/docs/api-reference/files/delete) endpoint.
    post:
      operationId: updateVectorStoreFileAttributes
      tags:
        - Vector stores
      summary: Update vector store file attributes
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store the file belongs to.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
            example: file-abc123
          description: The ID of the file to update attributes.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreFileAttributesRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Update vector store file attributes
        group: vector_stores
        returns: >-
          The updated [vector store
          file](https://platform.openai.com/docs/api-reference/vector-stores-files/file-object) object.
        examples:
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "usage_bytes": 1234,
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null,
              "chunking_strategy": {...},
              "attributes": {"key1": "value1", "key2": 2}
            }
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id} \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{"attributes": {"key1": "value1", "key2": 2}}'
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const vectorStoreFile = await client.vectorStores.files.update('file-abc123', {
                vector_store_id: 'vs_abc123',
                attributes: { foo: 'string' },
              });

              console.log(vectorStoreFile.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              vector_store_file = client.vector_stores.files.update(
                  file_id="file-abc123",
                  vector_store_id="vs_abc123",
                  attributes={
                      "foo": "string"
                  },
              )
              print(vector_store_file.id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                vectorStoreFile, err := client.VectorStores.Files.Update(
                  context.TODO(),
                  "vs_abc123",
                  "file-abc123",
                  openai.VectorStoreFileUpdateParams{
                    Attributes: map[string]openai.VectorStoreFileUpdateParamsAttributeUnion{
                    "foo": openai.VectorStoreFileUpdateParamsAttributeUnion{
                      OfString: openai.String("string"),
                    },
                    },
                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", vectorStoreFile.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.core.JsonValue;
              import com.openai.models.vectorstores.files.FileUpdateParams;
              import com.openai.models.vectorstores.files.VectorStoreFile;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileUpdateParams params = FileUpdateParams.builder()
                          .vectorStoreId("vs_abc123")
                          .fileId("file-abc123")
                          .attributes(FileUpdateParams.Attributes.builder()
                              .putAdditionalProperty("foo", JsonValue.from("string"))
                              .build())
                          .build();
                      VectorStoreFile vectorStoreFile = client.vectorStores().files().update(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              vector_store_file = openai.vector_stores.files.update(
                "file-abc123",
                vector_store_id: "vs_abc123",
                attributes: {foo: "string"}
              )

              puts(vector_store_file)
      description: Update attributes on a vector store file.
  /vector_stores/{vector_store_id}/files/{file_id}/content:
    get:
      operationId: retrieveVectorStoreFileContent
      tags:
        - Vector stores
      summary: Retrieve vector store file content
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store.
        - in: path
          name: file_id
          required: true
          schema:
            type: string
            example: file-abc123
          description: The ID of the file within the vector store.
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileContentResponse'
      x-oaiMeta:
        name: Retrieve vector store file content
        group: vector_stores
        returns: The parsed contents of the specified vector store file.
        examples:
          response: |
            {
              "file_id": "file-abc123",
              "filename": "example.txt",
              "attributes": {"key": "value"},
              "content": [
                {"type": "text", "text": "..."},
                ...
              ]
            }
          request:
            curl: |
              curl \
              https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123/content \
              -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              // Automatically fetches more pages as needed.
              for await (const fileContentResponse of client.vectorStores.files.content('file-abc123', {
                vector_store_id: 'vs_abc123',
              })) {
                console.log(fileContentResponse.text);
              }
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.vector_stores.files.content(
                  file_id="file-abc123",
                  vector_store_id="vs_abc123",
              )
              page = page.data[0]
              print(page.text)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.VectorStores.Files.Content(
                  context.TODO(),
                  "vs_abc123",
                  "file-abc123",
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.files.FileContentPage;
              import com.openai.models.vectorstores.files.FileContentParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      FileContentParams params = FileContentParams.builder()
                          .vectorStoreId("vs_abc123")
                          .fileId("file-abc123")
                          .build();
                      FileContentPage page = client.vectorStores().files().content(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.vector_stores.files.content("file-abc123", vector_store_id: "vs_abc123")

              puts(page)
      description: Retrieve the parsed contents of a vector store file.
  /vector_stores/{vector_store_id}/search:
    post:
      operationId: searchVectorStore
      tags:
        - Vector stores
      summary: Search vector store
      parameters:
        - in: path
          name: vector_store_id
          required: true
          schema:
            type: string
            example: vs_abc123
          description: The ID of the vector store to search.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/VectorStoreSearchRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreSearchResultsPage'
      x-oaiMeta:
        name: Search vector store
        group: vector_stores
        returns: A page of search results from the vector store.
        examples:
          response: |
            {
              "object": "vector_store.search_results.page",
              "search_query": "What is the return policy?",
              "data": [
                {
                  "file_id": "file_123",
                  "filename": "document.pdf",
                  "score": 0.95,
                  "attributes": {
                    "author": "John Doe",
                    "date": "2023-01-01"
                  },
                  "content": [
                    {
                      "type": "text",
                      "text": "Relevant chunk"
                    }
                  ]
                },
                {
                  "file_id": "file_456",
                  "filename": "notes.txt",
                  "score": 0.89,
                  "attributes": {
                    "author": "Jane Smith",
                    "date": "2023-01-02"
                  },
                  "content": [
                    {
                      "type": "text",
                      "text": "Sample text content from the vector store."
                    }
                  ]
                }
              ],
              "has_more": false,
              "next_page": null
            }
          request:
            curl: |
              curl -X POST \
              https://api.openai.com/v1/vector_stores/vs_abc123/search \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "Content-Type: application/json" \
              -d '{"query": "What is the return policy?", "filters": {...}}'
            node.js: >-
              import OpenAI from 'openai';


              const client = new OpenAI({
                apiKey: 'My API Key',
              });


              // Automatically fetches more pages as needed.

              for await (const vectorStoreSearchResponse of client.vectorStores.search('vs_abc123', { query:
              'string' })) {
                console.log(vectorStoreSearchResponse.file_id);
              }
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              page = client.vector_stores.search(
                  vector_store_id="vs_abc123",
                  query="string",
              )
              page = page.data[0]
              print(page.file_id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                page, err := client.VectorStores.Search(
                  context.TODO(),
                  "vs_abc123",
                  openai.VectorStoreSearchParams{
                    Query: openai.VectorStoreSearchParamsQueryUnion{
                      OfString: openai.String("string"),
                    },
                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", page)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.vectorstores.VectorStoreSearchPage;
              import com.openai.models.vectorstores.VectorStoreSearchParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VectorStoreSearchParams params = VectorStoreSearchParams.builder()
                          .vectorStoreId("vs_abc123")
                          .query("string")
                          .build();
                      VectorStoreSearchPage page = client.vectorStores().search(params);
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              page = openai.vector_stores.search("vs_abc123", query: "string")

              puts(page)
      description: Search a vector store for relevant chunks based on a query and file attributes filter.
  /conversations:
    post:
      tags:
        - Conversations
      summary: Create a conversation
      description: Create a conversation.
      operationId: createConversation
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateConversationBody'
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        name: Create a conversation
        group: conversations
        returns: >
          Returns a [Conversation](https://platform.openai.com/docs/api-reference/conversations/object)
          object.
        path: create
        examples:
          - title: Create a conversation.
            request:
              curl: |
                curl https://api.openai.com/v1/conversations \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "metadata": {"topic": "demo"},
                    "items": [
                      {
                        "type": "message",
                        "role": "user",
                        "content": "Hello!"
                      }
                    ]
                  }'
              javascript: |
                import OpenAI from "openai";
                const client = new OpenAI();

                const conversation = await client.conversations.create({
                  metadata: { topic: "demo" },
                  items: [
                    { type: "message", role: "user", content: "Hello!" }
                  ],
                });
                console.log(conversation);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                conversation = client.conversations.create()
                print(conversation.id)
              csharp: |
                using System;
                using System.Collections.Generic;
                using OpenAI.Conversations;

                OpenAIConversationClient client = new(
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                Conversation conversation = client.CreateConversation(
                    new CreateConversationOptions
                    {
                        Metadata = new Dictionary<string, string>
                        {
                            { "topic", "demo" }
                        },
                        Items =
                        {
                            new ConversationMessageInput
                            {
                                Role = "user",
                                Content = "Hello!",
                            }
                        }
                    }
                );
                Console.WriteLine(conversation.Id);
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const conversation = await client.conversations.create();

                console.log(conversation.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/conversations"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  conversation, err := client.Conversations.New(context.TODO(), conversations.ConversationNewParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", conversation.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.conversations.Conversation;
                import com.openai.models.conversations.ConversationCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Conversation conversation = client.conversations().create();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                conversation = openai.conversations.create

                puts(conversation)
            response: |
              {
                "id": "conv_123",
                "object": "conversation",
                "created_at": 1741900000,
                "metadata": {"topic": "demo"}
              }
  /conversations/{conversation_id}:
    get:
      tags:
        - Conversations
      summary: Retrieve a conversation
      description: Get a conversation
      operationId: getConversation
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to retrieve.
          required: true
          schema:
            example: conv_123
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        name: Retrieve a conversation
        group: conversations
        returns: >
          Returns a [Conversation](https://platform.openai.com/docs/api-reference/conversations/object)
          object.
        path: retrieve
        examples:
          - title: Retrieve a conversation
            request:
              curl: |
                curl https://api.openai.com/v1/conversations/conv_123 \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
              javascript: |
                import OpenAI from "openai";
                const client = new OpenAI();

                const conversation = await client.conversations.retrieve("conv_123");
                console.log(conversation);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                conversation = client.conversations.retrieve(
                    "conv_123",
                )
                print(conversation.id)
              csharp: |
                using System;
                using OpenAI.Conversations;

                OpenAIConversationClient client = new(
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                Conversation conversation = client.GetConversation("conv_123");
                Console.WriteLine(conversation.Id);
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const conversation = await client.conversations.retrieve('conv_123');

                console.log(conversation.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  conversation, err := client.Conversations.Get(context.TODO(), "conv_123")
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", conversation.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.conversations.Conversation;
                import com.openai.models.conversations.ConversationRetrieveParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        Conversation conversation = client.conversations().retrieve("conv_123");
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                conversation = openai.conversations.retrieve("conv_123")

                puts(conversation)
            response: |
              {
                "id": "conv_123",
                "object": "conversation",
                "created_at": 1741900000,
                "metadata": {"topic": "demo"}
              }
    delete:
      tags:
        - Conversations
      summary: Delete a conversation
      description: Delete a conversation. Items in the conversation will not be deleted.
      operationId: deleteConversation
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to delete.
          required: true
          schema:
            example: conv_123
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeletedConversationResource'
      x-oaiMeta:
        name: Delete a conversation
        group: conversations
        returns: |
          A success message.
        path: delete
        examples:
          - title: Delete a conversation
            request:
              curl: |
                curl -X DELETE https://api.openai.com/v1/conversations/conv_123 \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
              javascript: |
                import OpenAI from "openai";
                const client = new OpenAI();

                const deleted = await client.conversations.delete("conv_123");
                console.log(deleted);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                conversation_deleted_resource = client.conversations.delete(
                    "conv_123",
                )
                print(conversation_deleted_resource.id)
              csharp: |
                using System;
                using OpenAI.Conversations;

                OpenAIConversationClient client = new(
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                DeletedConversation deleted = client.DeleteConversation("conv_123");
                Console.WriteLine(deleted.Id);
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const conversationDeletedResource = await client.conversations.delete('conv_123');

                console.log(conversationDeletedResource.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  conversationDeletedResource, err := client.Conversations.Delete(context.TODO(), "conv_123")
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", conversationDeletedResource.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.conversations.ConversationDeleteParams;
                import com.openai.models.conversations.ConversationDeletedResource;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        ConversationDeletedResource conversationDeletedResource = client.conversations().delete("conv_123");
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                conversation_deleted_resource = openai.conversations.delete("conv_123")

                puts(conversation_deleted_resource)
            response: |
              {
                "id": "conv_123",
                "object": "conversation.deleted",
                "deleted": true
              }
    post:
      tags:
        - Conversations
      summary: Update a conversation
      description: Update a conversation
      operationId: updateConversation
      parameters:
        - name: conversation_id
          in: path
          description: The ID of the conversation to update.
          required: true
          schema:
            example: conv_123
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateConversationBody'
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ConversationResource'
      x-oaiMeta:
        name: Update a conversation
        group: conversations
        returns: >
          Returns the updated
          [Conversation](https://platform.openai.com/docs/api-reference/conversations/object) object.
        path: update
        examples:
          - title: Update conversation metadata
            request:
              curl: |
                curl https://api.openai.com/v1/conversations/conv_123 \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "metadata": {"topic": "project-x"}
                  }'
              javascript: |
                import OpenAI from "openai";
                const client = new OpenAI();

                const updated = await client.conversations.update(
                  "conv_123",
                  { metadata: { topic: "project-x" } }
                );
                console.log(updated);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                conversation = client.conversations.update(
                    conversation_id="conv_123",
                    metadata={
                        "foo": "string"
                    },
                )
                print(conversation.id)
              csharp: |
                using System;
                using System.Collections.Generic;
                using OpenAI.Conversations;

                OpenAIConversationClient client = new(
                    apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
                );

                Conversation updated = client.UpdateConversation(
                    conversationId: "conv_123",
                    new UpdateConversationOptions
                    {
                        Metadata = new Dictionary<string, string>
                        {
                            { "topic", "project-x" }
                        }
                    }
                );
                Console.WriteLine(updated.Id);
              node.js: >-
                import OpenAI from 'openai';


                const client = new OpenAI({
                  apiKey: 'My API Key',
                });


                const conversation = await client.conversations.update('conv_123', { metadata: { foo: 'string'
                } });


                console.log(conversation.id);
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/conversations"
                  "github.com/openai/openai-go/option"
                  "github.com/openai/openai-go/shared"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  conversation, err := client.Conversations.Update(
                    context.TODO(),
                    "conv_123",
                    conversations.ConversationUpdateParams{
                      Metadata: shared.Metadata{
                      "foo": "string",
                      },
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", conversation.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.core.JsonValue;
                import com.openai.models.conversations.Conversation;
                import com.openai.models.conversations.ConversationUpdateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        ConversationUpdateParams params = ConversationUpdateParams.builder()
                            .conversationId("conv_123")
                            .metadata(ConversationUpdateParams.Metadata.builder()
                                .putAdditionalProperty("foo", JsonValue.from("string"))
                                .build())
                            .build();
                        Conversation conversation = client.conversations().update(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                conversation = openai.conversations.update("conv_123", metadata: {foo: "string"})

                puts(conversation)
            response: |
              {
                "id": "conv_123",
                "object": "conversation",
                "created_at": 1741900000,
                "metadata": {"topic": "project-x"}
              }
  /videos:
    post:
      tags:
        - Videos
      summary: Create video
      description: Create a video
      operationId: createVideo
      parameters: []
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateVideoBody'
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVideoBody'
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VideoResource'
      x-oaiMeta:
        name: Create video
        group: videos
        path: create
        returns: Returns the newly created [video job](https://platform.openai.com/docs/api-reference/videos/object).
        examples:
          - title: Create a video render
            request:
              curl: |
                curl https://api.openai.com/v1/videos \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -F "model=sora-2" \
                  -F "prompt=A calico cat playing a piano on stage"
              javascript: |
                import OpenAI from 'openai';

                const openai = new OpenAI();

                const video = await openai.videos.create({ prompt: 'A calico cat playing a piano on stage' });

                console.log(video.id);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                video = client.videos.create(
                    prompt="x",
                )
                print(video.id)
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  video, err := client.Videos.New(context.TODO(), openai.VideoNewParams{
                    Prompt: "x",
                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", video.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.videos.Video;
                import com.openai.models.videos.VideoCreateParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        VideoCreateParams params = VideoCreateParams.builder()
                            .prompt("x")
                            .build();
                        Video video = client.videos().create(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                video = openai.videos.create(prompt: "x")

                puts(video)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const video = await client.videos.create({ prompt: 'x' });

                console.log(video.id);
            response: |
              {
                "id": "video_123",
                "object": "video",
                "model": "sora-2",
                "status": "queued",
                "progress": 0,
                "created_at": 1712697600,
                "size": "1024x1808",
                "seconds": "8",
                "quality": "standard"
              }
    get:
      tags:
        - Videos
      summary: List videos
      description: List videos
      operationId: ListVideos
      parameters:
        - name: limit
          in: query
          description: Number of items to retrieve
          required: false
          schema:
            type: integer
            minimum: 0
            maximum: 100
        - name: order
          in: query
          description: Sort order of results by timestamp. Use `asc` for ascending order or `desc` for descending order.
          required: false
          schema:
            $ref: '#/components/schemas/OrderEnum'
        - name: after
          in: query
          description: Identifier for the last item from the previous pagination request
          required: false
          schema:
            description: Identifier for the last item from the previous pagination request
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VideoListResource'
      x-oaiMeta:
        name: List videos
        group: videos
        path: list
        returns: >-
          Returns a paginated list of [video
          jobs](https://platform.openai.com/docs/api-reference/videos/object) for the organization.
        examples:
          - title: List recent videos
            request:
              curl: |
                curl https://api.openai.com/v1/videos \
                  -H "Authorization: Bearer $OPENAI_API_KEY"
              javascript: |
                import OpenAI from 'openai';

                const openai = new OpenAI();

                // Automatically fetches more pages as needed.
                for await (const video of openai.videos.list()) {
                  console.log(video.id);
                }
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                page = client.videos.list()
                page = page.data[0]
                print(page.id)
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  page, err := client.Videos.List(context.TODO(), openai.VideoListParams{

                  })
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", page)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.videos.VideoListPage;
                import com.openai.models.videos.VideoListParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        VideoListPage page = client.videos().list();
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                page = openai.videos.list

                puts(page)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                // Automatically fetches more pages as needed.
                for await (const video of client.videos.list()) {
                  console.log(video.id);
                }
            response: |
              {
                "data": [
                  {
                    "id": "video_123",
                    "object": "video",
                    "model": "sora-2",
                    "status": "completed"
                  }
                ],
                "object": "list"
              }
  /videos/{video_id}:
    get:
      tags:
        - Videos
      summary: Retrieve video
      description: Retrieve a video
      operationId: GetVideo
      parameters:
        - name: video_id
          in: path
          description: The identifier of the video to retrieve.
          required: true
          schema:
            example: video_123
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VideoResource'
      x-oaiMeta:
        name: Retrieve video
        group: videos
        path: retrieve
        returns: >-
          Returns the [video job](https://platform.openai.com/docs/api-reference/videos/object) matching the
          provided identifier.
        examples:
          response: ''
          request:
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const video = await client.videos.retrieve('video_123');

              console.log(video.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              video = client.videos.retrieve(
                  "video_123",
              )
              print(video.id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                video, err := client.Videos.Get(context.TODO(), "video_123")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", video.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.videos.Video;
              import com.openai.models.videos.VideoRetrieveParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      Video video = client.videos().retrieve("video_123");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              video = openai.videos.retrieve("video_123")

              puts(video)
    delete:
      tags:
        - Videos
      summary: Delete video
      description: Delete a video
      operationId: DeleteVideo
      parameters:
        - name: video_id
          in: path
          description: The identifier of the video to delete.
          required: true
          schema:
            example: video_123
            type: string
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeletedVideoResource'
      x-oaiMeta:
        name: Delete video
        group: videos
        path: delete
        returns: Returns the deleted video job metadata.
        examples:
          response: ''
          request:
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const video = await client.videos.delete('video_123');

              console.log(video.id);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              video = client.videos.delete(
                  "video_123",
              )
              print(video.id)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                video, err := client.Videos.Delete(context.TODO(), "video_123")
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", video.ID)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.videos.VideoDeleteParams;
              import com.openai.models.videos.VideoDeleteResponse;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      VideoDeleteResponse video = client.videos().delete("video_123");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              video = openai.videos.delete("video_123")

              puts(video)
  /videos/{video_id}/content:
    get:
      tags:
        - Videos
      summary: Retrieve video content
      description: Download video content
      operationId: RetrieveVideoContent
      parameters:
        - name: video_id
          in: path
          description: The identifier of the video whose media to download.
          required: true
          schema:
            example: video_123
            type: string
        - name: variant
          in: query
          description: Which downloadable asset to return. Defaults to the MP4 video.
          required: false
          schema:
            $ref: '#/components/schemas/VideoContentVariant'
      responses:
        '200':
          description: The video bytes or preview asset that matches the requested variant.
          content:
            video/mp4:
              schema:
                type: string
                format: binary
            image/webp:
              schema:
                type: string
                format: binary
            application/json:
              schema:
                type: string
      x-oaiMeta:
        name: Retrieve video content
        group: videos
        path: content
        returns: Streams the rendered video content for the specified video job.
        examples:
          response: ''
          request:
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const response = await client.videos.downloadContent('video_123');

              console.log(response);

              const content = await response.blob();
              console.log(content);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              response = client.videos.download_content(
                  video_id="video_123",
              )
              print(response)
              content = response.read()
              print(content)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                response, err := client.Videos.DownloadContent(
                  context.TODO(),
                  "video_123",
                  openai.VideoDownloadContentParams{

                  },
                )
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", response)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.core.http.HttpResponse;
              import com.openai.models.videos.VideoDownloadContentParams;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      HttpResponse response = client.videos().downloadContent("video_123");
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              response = openai.videos.download_content("video_123")

              puts(response)
  /videos/{video_id}/remix:
    post:
      tags:
        - Videos
      summary: Remix video
      description: Create a video remix
      operationId: CreateVideoRemix
      parameters:
        - name: video_id
          in: path
          description: The identifier of the completed video to remix.
          required: true
          schema:
            example: video_123
            type: string
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateVideoRemixBody'
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVideoRemixBody'
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VideoResource'
      x-oaiMeta:
        name: Remix video
        group: videos
        path: remix
        returns: >-
          Creates a remix of the specified [video
          job](https://platform.openai.com/docs/api-reference/videos/object) using the provided prompt.
        examples:
          - title: Remix a generated video
            request:
              curl: |
                curl -X POST https://api.openai.com/v1/videos/video_123/remix \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -d '{
                    "prompt": "Extend the scene with the cat taking a bow to the cheering audience"
                  }'
              javascript: >
                import OpenAI from 'openai';


                const client = new OpenAI();


                const video = await client.videos.remix('video_123', { prompt: 'Extend the scene with the cat
                taking a bow to the cheering audience' });


                console.log(video.id);
              python: |-
                from openai import OpenAI

                client = OpenAI(
                    api_key="My API Key",
                )
                video = client.videos.remix(
                    video_id="video_123",
                    prompt="x",
                )
                print(video.id)
              go: |
                package main

                import (
                  "context"
                  "fmt"

                  "github.com/openai/openai-go"
                  "github.com/openai/openai-go/option"
                )

                func main() {
                  client := openai.NewClient(
                    option.WithAPIKey("My API Key"),
                  )
                  video, err := client.Videos.Remix(
                    context.TODO(),
                    "video_123",
                    openai.VideoRemixParams{
                      Prompt: "x",
                    },
                  )
                  if err != nil {
                    panic(err.Error())
                  }
                  fmt.Printf("%+v\n", video.ID)
                }
              java: |-
                package com.openai.example;

                import com.openai.client.OpenAIClient;
                import com.openai.client.okhttp.OpenAIOkHttpClient;
                import com.openai.models.videos.Video;
                import com.openai.models.videos.VideoRemixParams;

                public final class Main {
                    private Main() {}

                    public static void main(String[] args) {
                        OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                        VideoRemixParams params = VideoRemixParams.builder()
                            .videoId("video_123")
                            .prompt("x")
                            .build();
                        Video video = client.videos().remix(params);
                    }
                }
              ruby: |-
                require "openai"

                openai = OpenAI::Client.new(api_key: "My API Key")

                video = openai.videos.remix("video_123", prompt: "x")

                puts(video)
              node.js: |-
                import OpenAI from 'openai';

                const client = new OpenAI({
                  apiKey: 'My API Key',
                });

                const video = await client.videos.remix('video_123', { prompt: 'x' });

                console.log(video.id);
            response: |
              {
                "id": "video_456",
                "object": "video",
                "model": "sora-2",
                "status": "queued",
                "progress": 0,
                "created_at": 1712698600,
                "size": "720x1280",
                "seconds": "8",
                "remixed_from_video_id": "video_123"
              }
  /responses/input_tokens:
    post:
      summary: Get input token counts
      description: Get input token counts
      operationId: Getinputtokencounts
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/TokenCountsBody'
          application/x-www-form-urlencoded:
            schema:
              $ref: '#/components/schemas/TokenCountsBody'
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TokenCountsResource'
      x-oaiMeta:
        name: Get input token counts
        group: responses
        returns: |
          The input token counts.
          ```json
          {
            object: "response.input_tokens"
            input_tokens: 123
          }
          ```
        examples:
          response: |
            {
              "object": "response.input_tokens",
              "input_tokens": 11
            }
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/responses/input_tokens \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-5",
                    "input": "Tell me a joke."
                  }'
            node.js: |-
              import OpenAI from 'openai';

              const client = new OpenAI({
                apiKey: 'My API Key',
              });

              const response = await client.responses.inputTokens.count();

              console.log(response.input_tokens);
            python: |-
              from openai import OpenAI

              client = OpenAI(
                  api_key="My API Key",
              )
              response = client.responses.input_tokens.count()
              print(response.input_tokens)
            go: |
              package main

              import (
                "context"
                "fmt"

                "github.com/openai/openai-go"
                "github.com/openai/openai-go/option"
                "github.com/openai/openai-go/responses"
              )

              func main() {
                client := openai.NewClient(
                  option.WithAPIKey("My API Key"),
                )
                response, err := client.Responses.InputTokens.Count(context.TODO(), responses.InputTokenCountParams{

                })
                if err != nil {
                  panic(err.Error())
                }
                fmt.Printf("%+v\n", response.InputTokens)
              }
            java: |-
              package com.openai.example;

              import com.openai.client.OpenAIClient;
              import com.openai.client.okhttp.OpenAIOkHttpClient;
              import com.openai.models.responses.inputtokens.InputTokenCountParams;
              import com.openai.models.responses.inputtokens.InputTokenCountResponse;

              public final class Main {
                  private Main() {}

                  public static void main(String[] args) {
                      OpenAIClient client = OpenAIOkHttpClient.fromEnv();

                      InputTokenCountResponse response = client.responses().inputTokens().count();
                  }
              }
            ruby: |-
              require "openai"

              openai = OpenAI::Client.new(api_key: "My API Key")

              response = openai.responses.input_tokens.count

              puts(response)
